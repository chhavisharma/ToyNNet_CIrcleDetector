{
  "nbformat": 4,
  "nbformat_minor": 0,
  "metadata": {
    "colab": {
      "name": "ScaleAI_ChhaviSharma.ipynb",
      "provenance": [],
      "collapsed_sections": [
        "XAiE4RCP_8io"
      ],
      "toc_visible": true,
      "machine_shape": "hm",
      "authorship_tag": "ABX9TyNZiwjbNVVFRVIlZ0qQehD7",
      "include_colab_link": true
    },
    "kernelspec": {
      "name": "python3",
      "display_name": "Python 3"
    },
    "accelerator": "GPU"
  },
  "cells": [
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "view-in-github",
        "colab_type": "text"
      },
      "source": [
        "<a href=\"https://colab.research.google.com/github/chhavisharma/scale/blob/master/ScaleAI_ChhaviSharma.ipynb\" target=\"_parent\"><img src=\"https://colab.research.google.com/assets/colab-badge.svg\" alt=\"Open In Colab\"/></a>"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "piaFqgT6tnVe",
        "colab_type": "text"
      },
      "source": [
        "# Mount Google Drive"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "yKLA31qYti9k",
        "colab_type": "code",
        "outputId": "bf332766-2045-47d6-8fd9-e82a95bd2210",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 54
        }
      },
      "source": [
        "import os\n",
        "from google.colab import drive\n",
        "\n",
        "DRIVE_MOUNT='/content/gdrive'\n",
        "drive.mount(DRIVE_MOUNT)\n",
        "\n",
        "# create folder to write data to\n",
        "WORK_FOLDER=os.path.join(DRIVE_MOUNT, 'My Drive', 'scaleAI')\n",
        "os.makedirs(WORK_FOLDER, exist_ok=True)"
      ],
      "execution_count": 106,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "Drive already mounted at /content/gdrive; to attempt to forcibly remount, call drive.mount(\"/content/gdrive\", force_remount=True).\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "gvbRCB9utwRS",
        "colab_type": "text"
      },
      "source": [
        "# Circle Detection"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "UMBMVaa8ZlNr",
        "colab_type": "text"
      },
      "source": [
        "##### Imports and Gloabals"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "IgumMmtkhVaz",
        "colab_type": "code",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 34
        },
        "outputId": "ecdda41d-6019-4d18-a898-ed8272205efa"
      },
      "source": [
        "import numpy as np\n",
        "from shapely.geometry.point import Point\n",
        "from skimage.draw import circle_perimeter_aa\n",
        "import matplotlib.pyplot as plt\n",
        "import pdb\n",
        "\n",
        "import torch\n",
        "import torchvision\n",
        "from torch import nn\n",
        "import torch.nn.functional as F\n",
        "from torchvision import transforms, datasets\n",
        "\n",
        "# Globals\n",
        "# loss depends on mac row, col, radius\n",
        "maxlength = torch.from_numpy(np.array([200.0,200.0,50.0])) \n",
        "torch.manual_seed(99)"
      ],
      "execution_count": 107,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "<torch._C.Generator at 0x7f040cf92530>"
            ]
          },
          "metadata": {
            "tags": []
          },
          "execution_count": 107
        }
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "zpTjzHTV-HsR",
        "colab_type": "text"
      },
      "source": [
        "#Training Routines"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "XAiE4RCP_8io",
        "colab_type": "text"
      },
      "source": [
        "##### Data Collection"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "CfLaMSXwt_-6",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "def noisy_circle(size, radius, noise):\n",
        "    img = np.zeros((size, size), dtype=np.float)\n",
        "\n",
        "    # Circle\n",
        "    row = np.random.randint(size)\n",
        "    col = np.random.randint(size)\n",
        "    rad = np.random.randint(10, max(10, radius))\n",
        "    draw_circle(img, row, col, rad)\n",
        "\n",
        "    # Noise\n",
        "    img += noise * np.random.rand(*img.shape)\n",
        "    return (row, col, rad), img"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "Pxvu9p7stzfU",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "def draw_circle(img, row, col, rad):\n",
        "    rr, cc, val = circle_perimeter_aa(row, col, rad)\n",
        "    valid = (\n",
        "        (rr >= 0) &\n",
        "        (rr < img.shape[0]) &\n",
        "        (cc >= 0) &\n",
        "        (cc < img.shape[1])\n",
        "    )\n",
        "    img[rr[valid], cc[valid]] = val[valid]"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "2JyEEKcI6oz3",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "def collect_data(img_count):\n",
        "    results = []\n",
        "    images  = []\n",
        "\n",
        "    for idx in range(0,img_count):\n",
        "        params, img = noisy_circle(200, 50, 2)\n",
        "        images.append(img)\n",
        "        results.append(params)\n",
        "\n",
        "    results = np.array(results)\n",
        "    images = np.array(images)\n",
        "\n",
        "    return images, results  \n",
        "\n",
        "def store_data():\n",
        "  '''\n",
        "  Roughly collect 80:20 train test data\n",
        "  with image generation parameters the same \n",
        "  as given in the test-main function\n",
        "  '''\n",
        "  images, results = collect_data(20000)\n",
        "  np.save(WORK_FOLDER+'/train_data_20k.npy',images)\n",
        "  np.save(WORK_FOLDER+'/train_labels_20k.npy',results)\n",
        "  print('finished train data collection')\n",
        "\n",
        "  images, results = collect_data(4000)\n",
        "  np.save(WORK_FOLDER+'/test_data_4k.npy',images)\n",
        "  np.save(WORK_FOLDER+'/test_labels_4k.npy',results)    \n",
        "  print('finished test data collection') \n",
        "\n",
        "# store_data()"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "k-nKAfKyABtj",
        "colab_type": "text"
      },
      "source": [
        "##### Model Definition"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "-6reFrni-ICO",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "class CircleDetector(torch.nn.Module):\n",
        "  def __init__(self):\n",
        "    super(CircleDetector, self).__init__()\n",
        "\n",
        "    # Backbone\n",
        "    self.conv0    = nn.Conv2d(1, 4, 3, padding=0)\n",
        "    self.conv0_bn = nn.BatchNorm2d(4, track_running_stats=True)\n",
        "\n",
        "    self.conv1    = nn.Conv2d(4, 16, 5, padding=0)\n",
        "    self.conv1_bn = nn.BatchNorm2d(16, track_running_stats=True)\n",
        "\n",
        "    self.conv2    = nn.Conv2d(16, 32, 5, padding=0) \n",
        "    self.conv2_bn = nn.BatchNorm2d(32, track_running_stats=True)\n",
        "    \n",
        "    self.conv3    = nn.Conv2d(32,64, 5, padding=0) \n",
        "    self.conv3_bn = nn.BatchNorm2d(64, track_running_stats=True)\n",
        "\n",
        "    self.conv4    = nn.Conv2d(64,128, 5, padding=0) \n",
        "    self.conv4_bn = nn.BatchNorm2d(128, track_running_stats=True)\n",
        "\n",
        "    self.pool1    = nn.MaxPool2d(2, stride=2, padding=0)\n",
        "\n",
        "    #Down\n",
        "    self.convInterm    = nn.Conv2d(128, 64, 3, padding=1) \n",
        "    self.convInterm_bn = nn.BatchNorm2d(64, track_running_stats=True)\n",
        "\n",
        "    #Projecting down to Y_hat dims\n",
        "    self.conv1x4       = nn.Conv2d(64, 3, 2)\n",
        "\n",
        "  def forward(self, x):\n",
        "\n",
        "    #Backbone\n",
        "    x = self.conv0(x) \n",
        "    x = self.conv0_bn(x)\n",
        "    F.relu(x, inplace=True)\n",
        "    x = self.pool1(x)\n",
        "\n",
        " \n",
        "    x = self.conv1(x) \n",
        "    x = self.conv1_bn(x)\n",
        "    F.relu(x, inplace=True)\n",
        "    x = self.pool1(x)\n",
        "\n",
        "\n",
        "    x = self.conv2(x) \n",
        "    x = self.conv2_bn(x)\n",
        "    F.relu(x, inplace=True)\n",
        "    x = self.pool1(x)\n",
        "\n",
        "    x = self.conv3(x) \n",
        "    x = self.conv3_bn(x)\n",
        "    F.relu(x, inplace=True)\n",
        "    x = self.pool1(x)\n",
        "\n",
        "    x = self.conv4(x) \n",
        "    x = self.conv4_bn(x)\n",
        "    F.relu(x, inplace=True)\n",
        "    x = self.pool1(x)\n",
        "\n",
        "    #Intermediate\n",
        "    x = self.convInterm(x) \n",
        "    x = self.convInterm_bn(x)\n",
        "    F.relu(x, inplace=True)\n",
        "\n",
        "    # Prediction\n",
        "    out =  self.conv1x4(x) \n",
        "    \n",
        "    # predict row,col,rad side-normalised\n",
        "    out = out.squeeze(-1).squeeze(-1)\n",
        "\n",
        "    return torch.sigmoid(out)\n",
        "\n",
        "def count_parameters(model):\n",
        "    return sum(p.numel() for p in model.parameters() if p.requires_grad)"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "22a4mHQZAGQ_",
        "colab_type": "text"
      },
      "source": [
        "##### Data Preprocessing"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "SuJptcPcW-Ah",
        "colab_type": "code",
        "outputId": "c4a8085c-67f7-4ca7-c949-272bb34aad28",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 69
        }
      },
      "source": [
        "class DatasetProcessed(torch.utils.data.Dataset):\n",
        "  def __init__(self, data, labels, type=\"train\", transform=\"None\"):\n",
        "    self.transform = transform\n",
        "    self.data = data\n",
        "    self.type = type\n",
        "    self.labels = labels\n",
        "\n",
        "  def __len__(self):\n",
        "    return len(self.data)\n",
        "\n",
        "  def __getitem__(self, idx):\n",
        "    img = self.data[idx]\n",
        "    label = self.labels[idx]\n",
        "\n",
        "    img = img.astype(np.float32)\n",
        "    img  = torch.from_numpy(img).unsqueeze(0) # add channel dimension\n",
        "    label = torch.from_numpy(label)\n",
        "\n",
        "    if(self.transform != None):\n",
        "      img = self.transform(img)\n",
        "\n",
        "    return (img, label)\n",
        "\n",
        "Norm_shift = [0.5]\n",
        "FRCNN_transform = torchvision.transforms.Compose([\n",
        "                               torchvision.transforms.Normalize(Norm_shift, Norm_shift)\n",
        "                             ])\n",
        "print('Loading Data')\n",
        "train_data   = np.load(WORK_FOLDER+'/train_data_20k.npy')\n",
        "train_label  = np.load(WORK_FOLDER+'/train_labels_20k.npy')\n",
        "print('Train Loaded')\n",
        "test_data   = np.load(WORK_FOLDER+'/test_data_4k.npy')\n",
        "test_label  = np.load(WORK_FOLDER+'/test_labels_4k.npy')\n",
        "print('Test loaded')\n",
        "\n",
        "dataset_train = DatasetProcessed(train_data, train_label, \"train\", None)\n",
        "dataset_test = DatasetProcessed(test_data, test_label, \"test\", None)\n"
      ],
      "execution_count": 9,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "Loading Data\n",
            "Train Loaded\n",
            "Test loaded\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "sLa64nd-n-q9",
        "colab_type": "code",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 69
        },
        "outputId": "bf209162-50a9-4374-bb08-6798c8af6162"
      },
      "source": [
        "dataloader_train = torch.utils.data.DataLoader(dataset_train,\n",
        "                                             batch_size=16, shuffle=True,\n",
        "                                             num_workers=4)\n",
        "\n",
        "dataloader_test = torch.utils.data.DataLoader(dataset_test,\n",
        "                                             batch_size=4, shuffle=True,\n",
        "                                             num_workers=4)\n",
        "\n",
        "# Test DataLoader\n",
        "for bid, (data, target) in enumerate(dataloader_train):\n",
        "  print(bid)\n",
        "  print(data.shape)\n",
        "  print(target.shape)\n",
        "  break"
      ],
      "execution_count": 112,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "0\n",
            "torch.Size([16, 1, 200, 200])\n",
            "torch.Size([16, 3])\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "NmPe00K1HV1W",
        "colab_type": "text"
      },
      "source": [
        "##### Loss Function"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "oR8aXVavphdR",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "def mse(true, pred): #L2\n",
        "    return ((true - pred)**2).sum()\n",
        "    \n",
        "def mae(true, pred): #L1\n",
        "  return (torch.abs(true - pred)).sum()\n",
        "\n",
        "def myLossFunction(pred, target, batchsize, scale):\n",
        "\n",
        "  target = target.type(torch.float64)\n",
        "  pred = pred.type(torch.float64)\n",
        "  \n",
        "  # Loss \n",
        "  loss  = mse(pred, target/scale) # side relative predictions\n",
        "  # loss  = mae(pred, target/scale) # side relative predictions\n",
        "  \n",
        "  custom_loss = (loss/batchsize)        \n",
        "  return custom_loss"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "4s6eeThKAZda",
        "colab_type": "text"
      },
      "source": [
        "##### Training Main"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "N2YMERZULGA-",
        "colab_type": "code",
        "outputId": "bf5b8eb1-58f6-455c-cf29-ecce73632816",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 1000
        }
      },
      "source": [
        "def logger(logs, logfile, cout='True'):\n",
        "    if(cout):\n",
        "      print(logs) \n",
        "\n",
        "    with open(logfile, 'a+') as the_file:\n",
        "      the_file.write(logs+'\\n')\n",
        "\n",
        "def train(model, device, train_loader, optimizer, criterion, epoch, logfile):\n",
        "  model.train()\n",
        "  running_loss = 0.0\n",
        "\n",
        "  for batch_idx, (data, target) in enumerate(train_loader):\n",
        "    data, target = data.to(device), target.to(device)\n",
        "    scale        = maxlength.to(device)\n",
        "    batch_size   = data.shape[0]\n",
        "    pred         = model(data)\n",
        "    loss         = criterion(pred, target, batch_size, scale)\n",
        "\n",
        "    optimizer.zero_grad()\n",
        "    loss.backward()\n",
        "    optimizer.step()\n",
        "\n",
        "    running_loss += loss.item()\n",
        "\n",
        "    ## TRACK PROGRESS PER BATCH\n",
        "    if batch_idx % 100 == 0:\n",
        "      logs = ('Train: epoch {} [{}/{}] current_loss: {:.6f}'.format(\n",
        "         epoch, batch_idx*batch_size, len(train_loader.dataset), loss))\n",
        "      logger(logs, logfile)\n",
        "\n",
        "  running_loss = running_loss/(len(train_loader)+1) \n",
        "  logs = ('Train: epoch {} Average loss: {:.4f}'.format(epoch, running_loss))\n",
        "  logger(logs, logfile)  \n",
        "\n",
        "  return running_loss\n",
        "\n",
        "def val(model, device, test_loader, optimizer, criterion, epoch, logfile):\n",
        "  model.eval()\n",
        "  test_loss = 0.0\n",
        "  with torch.no_grad():\n",
        "    for batch_idx, (data, target) in enumerate(test_loader):\n",
        "      \n",
        "      data, target = data.to(device), target.to(device)\n",
        "      scale        = maxlength.to(device)      \n",
        "      batch_size = data.shape[0]\n",
        "      output       = model(data)\n",
        "      loss         = criterion(output, target, batch_size, scale)\n",
        "      test_loss   += loss.item() \n",
        "      \n",
        "      ## TRACK PROGRESS PER BATCH\n",
        "      if batch_idx % 100 == 0:\n",
        "        logs = ('Val:   epoch {} [{}/{}] current_loss: {:.6f}'.format(\n",
        "         epoch, batch_idx*batch_size, len(test_loader.dataset), loss))\n",
        "        logger(logs, logfile) \n",
        "      \n",
        "  test_loss = test_loss/len(test_loader.dataset)\n",
        "  logs = ('Val:   epoch {} Average loss: {:.4f}\\n'.format(epoch, test_loss))\n",
        "  logger(logs, logfile) \n",
        "  logger('', logfile) \n",
        "\n",
        "  return test_loss\n",
        "  \n",
        "def training_main(model_name):\n",
        "  device = torch.device(\"cuda\" if torch.cuda.is_available() else \"cpu\")\n",
        "  \n",
        "  # Instantiate your network here:\n",
        "  model = CircleDetector()\n",
        "  model = model.to(device)\n",
        "  \n",
        "  # Training Configuration:\n",
        "  num_epochs    = 50\n",
        "  criterion     = myLossFunction\n",
        "  learning_rate = 5e-3\n",
        "  optimizer     = torch.optim.Adam(model.parameters(), lr=learning_rate)\n",
        "\n",
        "  # Init variables for plots:\n",
        "  train_loss   = []\n",
        "  val_loss     = []\n",
        "\n",
        "  logfile = WORK_FOLDER + '/'+str(model_name)+'_output.txt'\n",
        "\n",
        "  # Train network:\n",
        "  print(\"Device: \",device)\n",
        "\n",
        "  for epoch in range(num_epochs):\n",
        "    \n",
        "    print(\"Epoch %d/%d\" % (epoch, num_epochs))\n",
        "    avg_train_loss = train(model, device, dataloader_train, optimizer, criterion, epoch, logfile)\n",
        "    avg_val_loss   = val(model, device, dataloader_test, optimizer, criterion, epoch, logfile)\n",
        "    \n",
        "    # Track losses\n",
        "    train_loss.append(avg_train_loss)\n",
        "    val_loss.append(avg_val_loss)\n",
        "  \n",
        "  #Plot\n",
        "  plt.figure(1,figsize=(8,6))\n",
        "  plt.plot(np.arange(num_epochs),np.array(train_loss),'-r', label='Train Loss')\n",
        "  plt.plot(np.arange(num_epochs),np.array(val_loss),'-g', label='Validation Loss')\n",
        "  plt.xlabel('Epochs')\n",
        "  plt.ylabel('Loss')\n",
        "  plt.legend()\n",
        "  plt.title('LR='+str(learning_rate)+'|Optimizer=Adam'+'|LossF=MSE')\n",
        "  plt.savefig(WORK_FOLDER+'/LearningCurves_'+str(model_name)+'.png')\n",
        "  plt.show()\n",
        "\n",
        "  # UNCOMMENT to save Trained Model State Dict\n",
        "  print('Saving Model.')\n",
        "  torch.save(model.state_dict(), WORK_FOLDER + '/' +model_name+'.pth')  \n",
        "  return model\n",
        "\n",
        "# TRAIN AGAIN\n",
        "name = 'model_mse_20k_5e-3_50epochs'\n",
        "model = training_main(name)\n",
        "torch.save(model.state_dict(),WORK_FOLDER + '/'+name+'.pth')  "
      ],
      "execution_count": 88,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "Device:  cuda\n",
            "Epoch 0/50\n",
            "Train: epoch 0 [0/20000] current_loss: 0.277133\n",
            "Train: epoch 0 [1600/20000] current_loss: 0.094334\n",
            "Train: epoch 0 [3200/20000] current_loss: 0.051533\n",
            "Train: epoch 0 [4800/20000] current_loss: 0.070740\n",
            "Train: epoch 0 [6400/20000] current_loss: 0.058868\n",
            "Train: epoch 0 [8000/20000] current_loss: 0.049518\n",
            "Train: epoch 0 [9600/20000] current_loss: 0.023098\n",
            "Train: epoch 0 [11200/20000] current_loss: 0.017326\n",
            "Train: epoch 0 [12800/20000] current_loss: 0.012537\n",
            "Train: epoch 0 [14400/20000] current_loss: 0.020707\n",
            "Train: epoch 0 [16000/20000] current_loss: 0.025743\n",
            "Train: epoch 0 [17600/20000] current_loss: 0.012012\n",
            "Train: epoch 0 [19200/20000] current_loss: 0.012955\n",
            "Train: epoch 0 Average loss: 0.0433\n",
            "Val:   epoch 0 [0/4000] current_loss: 0.018642\n",
            "Val:   epoch 0 [400/4000] current_loss: 0.054841\n",
            "Val:   epoch 0 [800/4000] current_loss: 0.017080\n",
            "Val:   epoch 0 [1200/4000] current_loss: 0.024986\n",
            "Val:   epoch 0 [1600/4000] current_loss: 0.007936\n",
            "Val:   epoch 0 [2000/4000] current_loss: 0.054506\n",
            "Val:   epoch 0 [2400/4000] current_loss: 0.018889\n",
            "Val:   epoch 0 [2800/4000] current_loss: 0.023812\n",
            "Val:   epoch 0 [3200/4000] current_loss: 0.009441\n",
            "Val:   epoch 0 [3600/4000] current_loss: 0.022122\n",
            "Val:   epoch 0 Average loss: 0.0061\n",
            "\n",
            "\n",
            "Epoch 1/50\n",
            "Train: epoch 1 [0/20000] current_loss: 0.007262\n",
            "Train: epoch 1 [1600/20000] current_loss: 0.016709\n",
            "Train: epoch 1 [3200/20000] current_loss: 0.011599\n",
            "Train: epoch 1 [4800/20000] current_loss: 0.006238\n",
            "Train: epoch 1 [6400/20000] current_loss: 0.006323\n",
            "Train: epoch 1 [8000/20000] current_loss: 0.004105\n",
            "Train: epoch 1 [9600/20000] current_loss: 0.006320\n",
            "Train: epoch 1 [11200/20000] current_loss: 0.012642\n",
            "Train: epoch 1 [12800/20000] current_loss: 0.005772\n",
            "Train: epoch 1 [14400/20000] current_loss: 0.011585\n",
            "Train: epoch 1 [16000/20000] current_loss: 0.006002\n",
            "Train: epoch 1 [17600/20000] current_loss: 0.005033\n",
            "Train: epoch 1 [19200/20000] current_loss: 0.004045\n",
            "Train: epoch 1 Average loss: 0.0087\n",
            "Val:   epoch 1 [0/4000] current_loss: 0.001467\n",
            "Val:   epoch 1 [400/4000] current_loss: 0.000997\n",
            "Val:   epoch 1 [800/4000] current_loss: 0.002017\n",
            "Val:   epoch 1 [1200/4000] current_loss: 0.001266\n",
            "Val:   epoch 1 [1600/4000] current_loss: 0.001399\n",
            "Val:   epoch 1 [2000/4000] current_loss: 0.000543\n",
            "Val:   epoch 1 [2400/4000] current_loss: 0.015940\n",
            "Val:   epoch 1 [2800/4000] current_loss: 0.002318\n",
            "Val:   epoch 1 [3200/4000] current_loss: 0.006707\n",
            "Val:   epoch 1 [3600/4000] current_loss: 0.001803\n",
            "Val:   epoch 1 Average loss: 0.0013\n",
            "\n",
            "\n",
            "Epoch 2/50\n",
            "Train: epoch 2 [0/20000] current_loss: 0.006304\n",
            "Train: epoch 2 [1600/20000] current_loss: 0.006365\n",
            "Train: epoch 2 [3200/20000] current_loss: 0.009890\n",
            "Train: epoch 2 [4800/20000] current_loss: 0.006100\n",
            "Train: epoch 2 [6400/20000] current_loss: 0.008358\n",
            "Train: epoch 2 [8000/20000] current_loss: 0.009043\n",
            "Train: epoch 2 [9600/20000] current_loss: 0.005311\n",
            "Train: epoch 2 [11200/20000] current_loss: 0.005327\n",
            "Train: epoch 2 [12800/20000] current_loss: 0.004157\n",
            "Train: epoch 2 [14400/20000] current_loss: 0.004724\n",
            "Train: epoch 2 [16000/20000] current_loss: 0.003115\n",
            "Train: epoch 2 [17600/20000] current_loss: 0.003486\n",
            "Train: epoch 2 [19200/20000] current_loss: 0.002714\n",
            "Train: epoch 2 Average loss: 0.0060\n",
            "Val:   epoch 2 [0/4000] current_loss: 0.001037\n",
            "Val:   epoch 2 [400/4000] current_loss: 0.001260\n",
            "Val:   epoch 2 [800/4000] current_loss: 0.001212\n",
            "Val:   epoch 2 [1200/4000] current_loss: 0.001684\n",
            "Val:   epoch 2 [1600/4000] current_loss: 0.001112\n",
            "Val:   epoch 2 [2000/4000] current_loss: 0.001635\n",
            "Val:   epoch 2 [2400/4000] current_loss: 0.006323\n",
            "Val:   epoch 2 [2800/4000] current_loss: 0.002111\n",
            "Val:   epoch 2 [3200/4000] current_loss: 0.001329\n",
            "Val:   epoch 2 [3600/4000] current_loss: 0.007162\n",
            "Val:   epoch 2 Average loss: 0.0010\n",
            "\n",
            "\n",
            "Epoch 3/50\n",
            "Train: epoch 3 [0/20000] current_loss: 0.001956\n",
            "Train: epoch 3 [1600/20000] current_loss: 0.007345\n",
            "Train: epoch 3 [3200/20000] current_loss: 0.003830\n",
            "Train: epoch 3 [4800/20000] current_loss: 0.003052\n",
            "Train: epoch 3 [6400/20000] current_loss: 0.003594\n",
            "Train: epoch 3 [8000/20000] current_loss: 0.002851\n",
            "Train: epoch 3 [9600/20000] current_loss: 0.002236\n",
            "Train: epoch 3 [11200/20000] current_loss: 0.001716\n",
            "Train: epoch 3 [12800/20000] current_loss: 0.008265\n",
            "Train: epoch 3 [14400/20000] current_loss: 0.003175\n",
            "Train: epoch 3 [16000/20000] current_loss: 0.004182\n",
            "Train: epoch 3 [17600/20000] current_loss: 0.002304\n",
            "Train: epoch 3 [19200/20000] current_loss: 0.001055\n",
            "Train: epoch 3 Average loss: 0.0047\n",
            "Val:   epoch 3 [0/4000] current_loss: 0.002346\n",
            "Val:   epoch 3 [400/4000] current_loss: 0.003105\n",
            "Val:   epoch 3 [800/4000] current_loss: 0.004608\n",
            "Val:   epoch 3 [1200/4000] current_loss: 0.008105\n",
            "Val:   epoch 3 [1600/4000] current_loss: 0.001755\n",
            "Val:   epoch 3 [2000/4000] current_loss: 0.005727\n",
            "Val:   epoch 3 [2400/4000] current_loss: 0.005554\n",
            "Val:   epoch 3 [2800/4000] current_loss: 0.009554\n",
            "Val:   epoch 3 [3200/4000] current_loss: 0.007095\n",
            "Val:   epoch 3 [3600/4000] current_loss: 0.001003\n",
            "Val:   epoch 3 Average loss: 0.0014\n",
            "\n",
            "\n",
            "Epoch 4/50\n",
            "Train: epoch 4 [0/20000] current_loss: 0.003875\n",
            "Train: epoch 4 [1600/20000] current_loss: 0.007259\n",
            "Train: epoch 4 [3200/20000] current_loss: 0.004541\n",
            "Train: epoch 4 [4800/20000] current_loss: 0.011988\n",
            "Train: epoch 4 [6400/20000] current_loss: 0.005173\n",
            "Train: epoch 4 [8000/20000] current_loss: 0.001416\n",
            "Train: epoch 4 [9600/20000] current_loss: 0.003638\n",
            "Train: epoch 4 [11200/20000] current_loss: 0.008618\n",
            "Train: epoch 4 [12800/20000] current_loss: 0.004271\n",
            "Train: epoch 4 [14400/20000] current_loss: 0.001503\n",
            "Train: epoch 4 [16000/20000] current_loss: 0.002165\n",
            "Train: epoch 4 [17600/20000] current_loss: 0.002457\n",
            "Train: epoch 4 [19200/20000] current_loss: 0.002094\n",
            "Train: epoch 4 Average loss: 0.0042\n",
            "Val:   epoch 4 [0/4000] current_loss: 0.002840\n",
            "Val:   epoch 4 [400/4000] current_loss: 0.003638\n",
            "Val:   epoch 4 [800/4000] current_loss: 0.002702\n",
            "Val:   epoch 4 [1200/4000] current_loss: 0.002437\n",
            "Val:   epoch 4 [1600/4000] current_loss: 0.004662\n",
            "Val:   epoch 4 [2000/4000] current_loss: 0.000927\n",
            "Val:   epoch 4 [2400/4000] current_loss: 0.001571\n",
            "Val:   epoch 4 [2800/4000] current_loss: 0.002808\n",
            "Val:   epoch 4 [3200/4000] current_loss: 0.003143\n",
            "Val:   epoch 4 [3600/4000] current_loss: 0.002504\n",
            "Val:   epoch 4 Average loss: 0.0011\n",
            "\n",
            "\n",
            "Epoch 5/50\n",
            "Train: epoch 5 [0/20000] current_loss: 0.001904\n",
            "Train: epoch 5 [1600/20000] current_loss: 0.001889\n",
            "Train: epoch 5 [3200/20000] current_loss: 0.004425\n",
            "Train: epoch 5 [4800/20000] current_loss: 0.002330\n",
            "Train: epoch 5 [6400/20000] current_loss: 0.007468\n",
            "Train: epoch 5 [8000/20000] current_loss: 0.009512\n",
            "Train: epoch 5 [9600/20000] current_loss: 0.003018\n",
            "Train: epoch 5 [11200/20000] current_loss: 0.002004\n",
            "Train: epoch 5 [12800/20000] current_loss: 0.002550\n",
            "Train: epoch 5 [14400/20000] current_loss: 0.002857\n",
            "Train: epoch 5 [16000/20000] current_loss: 0.003237\n",
            "Train: epoch 5 [17600/20000] current_loss: 0.002311\n",
            "Train: epoch 5 [19200/20000] current_loss: 0.002299\n",
            "Train: epoch 5 Average loss: 0.0037\n",
            "Val:   epoch 5 [0/4000] current_loss: 0.000645\n",
            "Val:   epoch 5 [400/4000] current_loss: 0.002531\n",
            "Val:   epoch 5 [800/4000] current_loss: 0.003210\n",
            "Val:   epoch 5 [1200/4000] current_loss: 0.001380\n",
            "Val:   epoch 5 [1600/4000] current_loss: 0.007289\n",
            "Val:   epoch 5 [2000/4000] current_loss: 0.000852\n",
            "Val:   epoch 5 [2400/4000] current_loss: 0.002564\n",
            "Val:   epoch 5 [2800/4000] current_loss: 0.001510\n",
            "Val:   epoch 5 [3200/4000] current_loss: 0.001130\n",
            "Val:   epoch 5 [3600/4000] current_loss: 0.000809\n",
            "Val:   epoch 5 Average loss: 0.0007\n",
            "\n",
            "\n",
            "Epoch 6/50\n",
            "Train: epoch 6 [0/20000] current_loss: 0.001436\n",
            "Train: epoch 6 [1600/20000] current_loss: 0.001811\n",
            "Train: epoch 6 [3200/20000] current_loss: 0.002089\n",
            "Train: epoch 6 [4800/20000] current_loss: 0.002646\n",
            "Train: epoch 6 [6400/20000] current_loss: 0.004398\n",
            "Train: epoch 6 [8000/20000] current_loss: 0.002925\n",
            "Train: epoch 6 [9600/20000] current_loss: 0.001612\n",
            "Train: epoch 6 [11200/20000] current_loss: 0.002082\n",
            "Train: epoch 6 [12800/20000] current_loss: 0.001679\n",
            "Train: epoch 6 [14400/20000] current_loss: 0.002301\n",
            "Train: epoch 6 [16000/20000] current_loss: 0.002955\n",
            "Train: epoch 6 [17600/20000] current_loss: 0.005405\n",
            "Train: epoch 6 [19200/20000] current_loss: 0.001747\n",
            "Train: epoch 6 Average loss: 0.0033\n",
            "Val:   epoch 6 [0/4000] current_loss: 0.002739\n",
            "Val:   epoch 6 [400/4000] current_loss: 0.001589\n",
            "Val:   epoch 6 [800/4000] current_loss: 0.001761\n",
            "Val:   epoch 6 [1200/4000] current_loss: 0.001255\n",
            "Val:   epoch 6 [1600/4000] current_loss: 0.002616\n",
            "Val:   epoch 6 [2000/4000] current_loss: 0.003322\n",
            "Val:   epoch 6 [2400/4000] current_loss: 0.002243\n",
            "Val:   epoch 6 [2800/4000] current_loss: 0.003050\n",
            "Val:   epoch 6 [3200/4000] current_loss: 0.001340\n",
            "Val:   epoch 6 [3600/4000] current_loss: 0.002604\n",
            "Val:   epoch 6 Average loss: 0.0008\n",
            "\n",
            "\n",
            "Epoch 7/50\n",
            "Train: epoch 7 [0/20000] current_loss: 0.002610\n",
            "Train: epoch 7 [1600/20000] current_loss: 0.001494\n",
            "Train: epoch 7 [3200/20000] current_loss: 0.002056\n",
            "Train: epoch 7 [4800/20000] current_loss: 0.003571\n",
            "Train: epoch 7 [6400/20000] current_loss: 0.001291\n",
            "Train: epoch 7 [8000/20000] current_loss: 0.004059\n",
            "Train: epoch 7 [9600/20000] current_loss: 0.001876\n",
            "Train: epoch 7 [11200/20000] current_loss: 0.002847\n",
            "Train: epoch 7 [12800/20000] current_loss: 0.001353\n",
            "Train: epoch 7 [14400/20000] current_loss: 0.001505\n",
            "Train: epoch 7 [16000/20000] current_loss: 0.001813\n",
            "Train: epoch 7 [17600/20000] current_loss: 0.002632\n",
            "Train: epoch 7 [19200/20000] current_loss: 0.002557\n",
            "Train: epoch 7 Average loss: 0.0030\n",
            "Val:   epoch 7 [0/4000] current_loss: 0.002051\n",
            "Val:   epoch 7 [400/4000] current_loss: 0.000885\n",
            "Val:   epoch 7 [800/4000] current_loss: 0.000798\n",
            "Val:   epoch 7 [1200/4000] current_loss: 0.000509\n",
            "Val:   epoch 7 [1600/4000] current_loss: 0.002042\n",
            "Val:   epoch 7 [2000/4000] current_loss: 0.003991\n",
            "Val:   epoch 7 [2400/4000] current_loss: 0.003306\n",
            "Val:   epoch 7 [2800/4000] current_loss: 0.000693\n",
            "Val:   epoch 7 [3200/4000] current_loss: 0.001690\n",
            "Val:   epoch 7 [3600/4000] current_loss: 0.001019\n",
            "Val:   epoch 7 Average loss: 0.0006\n",
            "\n",
            "\n",
            "Epoch 8/50\n",
            "Train: epoch 8 [0/20000] current_loss: 0.002814\n",
            "Train: epoch 8 [1600/20000] current_loss: 0.001123\n",
            "Train: epoch 8 [3200/20000] current_loss: 0.001857\n",
            "Train: epoch 8 [4800/20000] current_loss: 0.001752\n",
            "Train: epoch 8 [6400/20000] current_loss: 0.002444\n",
            "Train: epoch 8 [8000/20000] current_loss: 0.004324\n",
            "Train: epoch 8 [9600/20000] current_loss: 0.001791\n",
            "Train: epoch 8 [11200/20000] current_loss: 0.001694\n",
            "Train: epoch 8 [12800/20000] current_loss: 0.001480\n",
            "Train: epoch 8 [14400/20000] current_loss: 0.002440\n",
            "Train: epoch 8 [16000/20000] current_loss: 0.002084\n",
            "Train: epoch 8 [17600/20000] current_loss: 0.001007\n",
            "Train: epoch 8 [19200/20000] current_loss: 0.001246\n",
            "Train: epoch 8 Average loss: 0.0027\n",
            "Val:   epoch 8 [0/4000] current_loss: 0.005072\n",
            "Val:   epoch 8 [400/4000] current_loss: 0.001519\n",
            "Val:   epoch 8 [800/4000] current_loss: 0.003144\n",
            "Val:   epoch 8 [1200/4000] current_loss: 0.002004\n",
            "Val:   epoch 8 [1600/4000] current_loss: 0.011294\n",
            "Val:   epoch 8 [2000/4000] current_loss: 0.000339\n",
            "Val:   epoch 8 [2400/4000] current_loss: 0.001393\n",
            "Val:   epoch 8 [2800/4000] current_loss: 0.001084\n",
            "Val:   epoch 8 [3200/4000] current_loss: 0.000394\n",
            "Val:   epoch 8 [3600/4000] current_loss: 0.002914\n",
            "Val:   epoch 8 Average loss: 0.0006\n",
            "\n",
            "\n",
            "Epoch 9/50\n",
            "Train: epoch 9 [0/20000] current_loss: 0.002644\n",
            "Train: epoch 9 [1600/20000] current_loss: 0.002040\n",
            "Train: epoch 9 [3200/20000] current_loss: 0.004975\n",
            "Train: epoch 9 [4800/20000] current_loss: 0.001668\n",
            "Train: epoch 9 [6400/20000] current_loss: 0.001396\n",
            "Train: epoch 9 [8000/20000] current_loss: 0.002359\n",
            "Train: epoch 9 [9600/20000] current_loss: 0.001419\n",
            "Train: epoch 9 [11200/20000] current_loss: 0.001393\n",
            "Train: epoch 9 [12800/20000] current_loss: 0.001457\n",
            "Train: epoch 9 [14400/20000] current_loss: 0.002117\n",
            "Train: epoch 9 [16000/20000] current_loss: 0.002034\n",
            "Train: epoch 9 [17600/20000] current_loss: 0.001135\n",
            "Train: epoch 9 [19200/20000] current_loss: 0.001768\n",
            "Train: epoch 9 Average loss: 0.0025\n",
            "Val:   epoch 9 [0/4000] current_loss: 0.003706\n",
            "Val:   epoch 9 [400/4000] current_loss: 0.001349\n",
            "Val:   epoch 9 [800/4000] current_loss: 0.001745\n",
            "Val:   epoch 9 [1200/4000] current_loss: 0.002965\n",
            "Val:   epoch 9 [1600/4000] current_loss: 0.002182\n",
            "Val:   epoch 9 [2000/4000] current_loss: 0.005164\n",
            "Val:   epoch 9 [2400/4000] current_loss: 0.003794\n",
            "Val:   epoch 9 [2800/4000] current_loss: 0.001765\n",
            "Val:   epoch 9 [3200/4000] current_loss: 0.003503\n",
            "Val:   epoch 9 [3600/4000] current_loss: 0.002528\n",
            "Val:   epoch 9 Average loss: 0.0009\n",
            "\n",
            "\n",
            "Epoch 10/50\n",
            "Train: epoch 10 [0/20000] current_loss: 0.001806\n",
            "Train: epoch 10 [1600/20000] current_loss: 0.001774\n",
            "Train: epoch 10 [3200/20000] current_loss: 0.002942\n",
            "Train: epoch 10 [4800/20000] current_loss: 0.001359\n",
            "Train: epoch 10 [6400/20000] current_loss: 0.001411\n",
            "Train: epoch 10 [8000/20000] current_loss: 0.001892\n",
            "Train: epoch 10 [9600/20000] current_loss: 0.001611\n",
            "Train: epoch 10 [11200/20000] current_loss: 0.000822\n",
            "Train: epoch 10 [12800/20000] current_loss: 0.000667\n",
            "Train: epoch 10 [14400/20000] current_loss: 0.001241\n",
            "Train: epoch 10 [16000/20000] current_loss: 0.001082\n",
            "Train: epoch 10 [17600/20000] current_loss: 0.001678\n",
            "Train: epoch 10 [19200/20000] current_loss: 0.000915\n",
            "Train: epoch 10 Average loss: 0.0025\n",
            "Val:   epoch 10 [0/4000] current_loss: 0.002184\n",
            "Val:   epoch 10 [400/4000] current_loss: 0.001479\n",
            "Val:   epoch 10 [800/4000] current_loss: 0.004642\n",
            "Val:   epoch 10 [1200/4000] current_loss: 0.002674\n",
            "Val:   epoch 10 [1600/4000] current_loss: 0.001797\n",
            "Val:   epoch 10 [2000/4000] current_loss: 0.002187\n",
            "Val:   epoch 10 [2400/4000] current_loss: 0.001801\n",
            "Val:   epoch 10 [2800/4000] current_loss: 0.002659\n",
            "Val:   epoch 10 [3200/4000] current_loss: 0.002226\n",
            "Val:   epoch 10 [3600/4000] current_loss: 0.002673\n",
            "Val:   epoch 10 Average loss: 0.0007\n",
            "\n",
            "\n",
            "Epoch 11/50\n",
            "Train: epoch 11 [0/20000] current_loss: 0.000889\n",
            "Train: epoch 11 [1600/20000] current_loss: 0.001083\n",
            "Train: epoch 11 [3200/20000] current_loss: 0.001875\n",
            "Train: epoch 11 [4800/20000] current_loss: 0.001570\n",
            "Train: epoch 11 [6400/20000] current_loss: 0.001808\n",
            "Train: epoch 11 [8000/20000] current_loss: 0.001068\n",
            "Train: epoch 11 [9600/20000] current_loss: 0.001840\n",
            "Train: epoch 11 [11200/20000] current_loss: 0.001709\n",
            "Train: epoch 11 [12800/20000] current_loss: 0.000958\n",
            "Train: epoch 11 [14400/20000] current_loss: 0.000887\n",
            "Train: epoch 11 [16000/20000] current_loss: 0.001196\n",
            "Train: epoch 11 [17600/20000] current_loss: 0.001464\n",
            "Train: epoch 11 [19200/20000] current_loss: 0.000891\n",
            "Train: epoch 11 Average loss: 0.0022\n",
            "Val:   epoch 11 [0/4000] current_loss: 0.015735\n",
            "Val:   epoch 11 [400/4000] current_loss: 0.003004\n",
            "Val:   epoch 11 [800/4000] current_loss: 0.006064\n",
            "Val:   epoch 11 [1200/4000] current_loss: 0.007005\n",
            "Val:   epoch 11 [1600/4000] current_loss: 0.004618\n",
            "Val:   epoch 11 [2000/4000] current_loss: 0.005068\n",
            "Val:   epoch 11 [2400/4000] current_loss: 0.007728\n",
            "Val:   epoch 11 [2800/4000] current_loss: 0.006767\n",
            "Val:   epoch 11 [3200/4000] current_loss: 0.005821\n",
            "Val:   epoch 11 [3600/4000] current_loss: 0.002775\n",
            "Val:   epoch 11 Average loss: 0.0021\n",
            "\n",
            "\n",
            "Epoch 12/50\n",
            "Train: epoch 12 [0/20000] current_loss: 0.002262\n",
            "Train: epoch 12 [1600/20000] current_loss: 0.001057\n",
            "Train: epoch 12 [3200/20000] current_loss: 0.002554\n",
            "Train: epoch 12 [4800/20000] current_loss: 0.001267\n",
            "Train: epoch 12 [6400/20000] current_loss: 0.001911\n",
            "Train: epoch 12 [8000/20000] current_loss: 0.002625\n",
            "Train: epoch 12 [9600/20000] current_loss: 0.000551\n",
            "Train: epoch 12 [11200/20000] current_loss: 0.000845\n",
            "Train: epoch 12 [12800/20000] current_loss: 0.000615\n",
            "Train: epoch 12 [14400/20000] current_loss: 0.001871\n",
            "Train: epoch 12 [16000/20000] current_loss: 0.001659\n",
            "Train: epoch 12 [17600/20000] current_loss: 0.001514\n",
            "Train: epoch 12 [19200/20000] current_loss: 0.000826\n",
            "Train: epoch 12 Average loss: 0.0021\n",
            "Val:   epoch 12 [0/4000] current_loss: 0.044548\n",
            "Val:   epoch 12 [400/4000] current_loss: 0.001234\n",
            "Val:   epoch 12 [800/4000] current_loss: 0.006697\n",
            "Val:   epoch 12 [1200/4000] current_loss: 0.011705\n",
            "Val:   epoch 12 [1600/4000] current_loss: 0.008562\n",
            "Val:   epoch 12 [2000/4000] current_loss: 0.009002\n",
            "Val:   epoch 12 [2400/4000] current_loss: 0.029550\n",
            "Val:   epoch 12 [2800/4000] current_loss: 0.003383\n",
            "Val:   epoch 12 [3200/4000] current_loss: 0.002140\n",
            "Val:   epoch 12 [3600/4000] current_loss: 0.006349\n",
            "Val:   epoch 12 Average loss: 0.0040\n",
            "\n",
            "\n",
            "Epoch 13/50\n",
            "Train: epoch 13 [0/20000] current_loss: 0.002745\n",
            "Train: epoch 13 [1600/20000] current_loss: 0.000681\n",
            "Train: epoch 13 [3200/20000] current_loss: 0.000638\n",
            "Train: epoch 13 [4800/20000] current_loss: 0.001736\n",
            "Train: epoch 13 [6400/20000] current_loss: 0.002006\n",
            "Train: epoch 13 [8000/20000] current_loss: 0.002081\n",
            "Train: epoch 13 [9600/20000] current_loss: 0.001015\n",
            "Train: epoch 13 [11200/20000] current_loss: 0.001172\n",
            "Train: epoch 13 [12800/20000] current_loss: 0.001252\n",
            "Train: epoch 13 [14400/20000] current_loss: 0.001371\n",
            "Train: epoch 13 [16000/20000] current_loss: 0.001750\n",
            "Train: epoch 13 [17600/20000] current_loss: 0.000979\n",
            "Train: epoch 13 [19200/20000] current_loss: 0.001342\n",
            "Train: epoch 13 Average loss: 0.0022\n",
            "Val:   epoch 13 [0/4000] current_loss: 0.001805\n",
            "Val:   epoch 13 [400/4000] current_loss: 0.001482\n",
            "Val:   epoch 13 [800/4000] current_loss: 0.001952\n",
            "Val:   epoch 13 [1200/4000] current_loss: 0.001969\n",
            "Val:   epoch 13 [1600/4000] current_loss: 0.002253\n",
            "Val:   epoch 13 [2000/4000] current_loss: 0.000973\n",
            "Val:   epoch 13 [2400/4000] current_loss: 0.001401\n",
            "Val:   epoch 13 [2800/4000] current_loss: 0.003771\n",
            "Val:   epoch 13 [3200/4000] current_loss: 0.001725\n",
            "Val:   epoch 13 [3600/4000] current_loss: 0.001089\n",
            "Val:   epoch 13 Average loss: 0.0006\n",
            "\n",
            "\n",
            "Epoch 14/50\n",
            "Train: epoch 14 [0/20000] current_loss: 0.002125\n",
            "Train: epoch 14 [1600/20000] current_loss: 0.001388\n",
            "Train: epoch 14 [3200/20000] current_loss: 0.000685\n",
            "Train: epoch 14 [4800/20000] current_loss: 0.000806\n",
            "Train: epoch 14 [6400/20000] current_loss: 0.000505\n",
            "Train: epoch 14 [8000/20000] current_loss: 0.001085\n",
            "Train: epoch 14 [9600/20000] current_loss: 0.000593\n",
            "Train: epoch 14 [11200/20000] current_loss: 0.001700\n",
            "Train: epoch 14 [12800/20000] current_loss: 0.002112\n",
            "Train: epoch 14 [14400/20000] current_loss: 0.001306\n",
            "Train: epoch 14 [16000/20000] current_loss: 0.000848\n",
            "Train: epoch 14 [17600/20000] current_loss: 0.001857\n",
            "Train: epoch 14 [19200/20000] current_loss: 0.000964\n",
            "Train: epoch 14 Average loss: 0.0019\n",
            "Val:   epoch 14 [0/4000] current_loss: 0.000483\n",
            "Val:   epoch 14 [400/4000] current_loss: 0.000656\n",
            "Val:   epoch 14 [800/4000] current_loss: 0.000844\n",
            "Val:   epoch 14 [1200/4000] current_loss: 0.000808\n",
            "Val:   epoch 14 [1600/4000] current_loss: 0.000623\n",
            "Val:   epoch 14 [2000/4000] current_loss: 0.001125\n",
            "Val:   epoch 14 [2400/4000] current_loss: 0.001134\n",
            "Val:   epoch 14 [2800/4000] current_loss: 0.022706\n",
            "Val:   epoch 14 [3200/4000] current_loss: 0.000138\n",
            "Val:   epoch 14 [3600/4000] current_loss: 0.000203\n",
            "Val:   epoch 14 Average loss: 0.0004\n",
            "\n",
            "\n",
            "Epoch 15/50\n",
            "Train: epoch 15 [0/20000] current_loss: 0.001280\n",
            "Train: epoch 15 [1600/20000] current_loss: 0.001552\n",
            "Train: epoch 15 [3200/20000] current_loss: 0.001469\n",
            "Train: epoch 15 [4800/20000] current_loss: 0.002114\n",
            "Train: epoch 15 [6400/20000] current_loss: 0.001146\n",
            "Train: epoch 15 [8000/20000] current_loss: 0.002543\n",
            "Train: epoch 15 [9600/20000] current_loss: 0.001362\n",
            "Train: epoch 15 [11200/20000] current_loss: 0.002635\n",
            "Train: epoch 15 [12800/20000] current_loss: 0.000830\n",
            "Train: epoch 15 [14400/20000] current_loss: 0.000607\n",
            "Train: epoch 15 [16000/20000] current_loss: 0.002633\n",
            "Train: epoch 15 [17600/20000] current_loss: 0.001662\n",
            "Train: epoch 15 [19200/20000] current_loss: 0.001877\n",
            "Train: epoch 15 Average loss: 0.0019\n",
            "Val:   epoch 15 [0/4000] current_loss: 0.001881\n",
            "Val:   epoch 15 [400/4000] current_loss: 0.000398\n",
            "Val:   epoch 15 [800/4000] current_loss: 0.000309\n",
            "Val:   epoch 15 [1200/4000] current_loss: 0.000526\n",
            "Val:   epoch 15 [1600/4000] current_loss: 0.000325\n",
            "Val:   epoch 15 [2000/4000] current_loss: 0.000594\n",
            "Val:   epoch 15 [2400/4000] current_loss: 0.001276\n",
            "Val:   epoch 15 [2800/4000] current_loss: 0.000792\n",
            "Val:   epoch 15 [3200/4000] current_loss: 0.000299\n",
            "Val:   epoch 15 [3600/4000] current_loss: 0.001133\n",
            "Val:   epoch 15 Average loss: 0.0004\n",
            "\n",
            "\n",
            "Epoch 16/50\n",
            "Train: epoch 16 [0/20000] current_loss: 0.000905\n",
            "Train: epoch 16 [1600/20000] current_loss: 0.001154\n",
            "Train: epoch 16 [3200/20000] current_loss: 0.000752\n",
            "Train: epoch 16 [4800/20000] current_loss: 0.000906\n",
            "Train: epoch 16 [6400/20000] current_loss: 0.002117\n",
            "Train: epoch 16 [8000/20000] current_loss: 0.000501\n",
            "Train: epoch 16 [9600/20000] current_loss: 0.001082\n",
            "Train: epoch 16 [11200/20000] current_loss: 0.000541\n",
            "Train: epoch 16 [12800/20000] current_loss: 0.000919\n",
            "Train: epoch 16 [14400/20000] current_loss: 0.001202\n",
            "Train: epoch 16 [16000/20000] current_loss: 0.001802\n",
            "Train: epoch 16 [17600/20000] current_loss: 0.001568\n",
            "Train: epoch 16 [19200/20000] current_loss: 0.002805\n",
            "Train: epoch 16 Average loss: 0.0018\n",
            "Val:   epoch 16 [0/4000] current_loss: 0.001164\n",
            "Val:   epoch 16 [400/4000] current_loss: 0.001229\n",
            "Val:   epoch 16 [800/4000] current_loss: 0.001812\n",
            "Val:   epoch 16 [1200/4000] current_loss: 0.001687\n",
            "Val:   epoch 16 [1600/4000] current_loss: 0.002932\n",
            "Val:   epoch 16 [2000/4000] current_loss: 0.001307\n",
            "Val:   epoch 16 [2400/4000] current_loss: 0.002113\n",
            "Val:   epoch 16 [2800/4000] current_loss: 0.001190\n",
            "Val:   epoch 16 [3200/4000] current_loss: 0.000860\n",
            "Val:   epoch 16 [3600/4000] current_loss: 0.000657\n",
            "Val:   epoch 16 Average loss: 0.0006\n",
            "\n",
            "\n",
            "Epoch 17/50\n",
            "Train: epoch 17 [0/20000] current_loss: 0.001305\n",
            "Train: epoch 17 [1600/20000] current_loss: 0.000496\n",
            "Train: epoch 17 [3200/20000] current_loss: 0.001835\n",
            "Train: epoch 17 [4800/20000] current_loss: 0.002096\n",
            "Train: epoch 17 [6400/20000] current_loss: 0.001317\n",
            "Train: epoch 17 [8000/20000] current_loss: 0.002071\n",
            "Train: epoch 17 [9600/20000] current_loss: 0.001867\n",
            "Train: epoch 17 [11200/20000] current_loss: 0.001118\n",
            "Train: epoch 17 [12800/20000] current_loss: 0.000782\n",
            "Train: epoch 17 [14400/20000] current_loss: 0.000789\n",
            "Train: epoch 17 [16000/20000] current_loss: 0.001927\n",
            "Train: epoch 17 [17600/20000] current_loss: 0.000825\n",
            "Train: epoch 17 [19200/20000] current_loss: 0.001328\n",
            "Train: epoch 17 Average loss: 0.0018\n",
            "Val:   epoch 17 [0/4000] current_loss: 0.001044\n",
            "Val:   epoch 17 [400/4000] current_loss: 0.001102\n",
            "Val:   epoch 17 [800/4000] current_loss: 0.001064\n",
            "Val:   epoch 17 [1200/4000] current_loss: 0.000248\n",
            "Val:   epoch 17 [1600/4000] current_loss: 0.000949\n",
            "Val:   epoch 17 [2000/4000] current_loss: 0.001092\n",
            "Val:   epoch 17 [2400/4000] current_loss: 0.002466\n",
            "Val:   epoch 17 [2800/4000] current_loss: 0.000851\n",
            "Val:   epoch 17 [3200/4000] current_loss: 0.001795\n",
            "Val:   epoch 17 [3600/4000] current_loss: 0.000853\n",
            "Val:   epoch 17 Average loss: 0.0005\n",
            "\n",
            "\n",
            "Epoch 18/50\n",
            "Train: epoch 18 [0/20000] current_loss: 0.000867\n",
            "Train: epoch 18 [1600/20000] current_loss: 0.000482\n",
            "Train: epoch 18 [3200/20000] current_loss: 0.001747\n",
            "Train: epoch 18 [4800/20000] current_loss: 0.000822\n",
            "Train: epoch 18 [6400/20000] current_loss: 0.000890\n",
            "Train: epoch 18 [8000/20000] current_loss: 0.001933\n",
            "Train: epoch 18 [9600/20000] current_loss: 0.000954\n",
            "Train: epoch 18 [11200/20000] current_loss: 0.000628\n",
            "Train: epoch 18 [12800/20000] current_loss: 0.000618\n",
            "Train: epoch 18 [14400/20000] current_loss: 0.001076\n",
            "Train: epoch 18 [16000/20000] current_loss: 0.001352\n",
            "Train: epoch 18 [17600/20000] current_loss: 0.001232\n",
            "Train: epoch 18 [19200/20000] current_loss: 0.001220\n",
            "Train: epoch 18 Average loss: 0.0017\n",
            "Val:   epoch 18 [0/4000] current_loss: 0.001668\n",
            "Val:   epoch 18 [400/4000] current_loss: 0.000753\n",
            "Val:   epoch 18 [800/4000] current_loss: 0.000754\n",
            "Val:   epoch 18 [1200/4000] current_loss: 0.000471\n",
            "Val:   epoch 18 [1600/4000] current_loss: 0.000833\n",
            "Val:   epoch 18 [2000/4000] current_loss: 0.000822\n",
            "Val:   epoch 18 [2400/4000] current_loss: 0.000875\n",
            "Val:   epoch 18 [2800/4000] current_loss: 0.001538\n",
            "Val:   epoch 18 [3200/4000] current_loss: 0.000672\n",
            "Val:   epoch 18 [3600/4000] current_loss: 0.001600\n",
            "Val:   epoch 18 Average loss: 0.0005\n",
            "\n",
            "\n",
            "Epoch 19/50\n",
            "Train: epoch 19 [0/20000] current_loss: 0.001007\n",
            "Train: epoch 19 [1600/20000] current_loss: 0.000924\n",
            "Train: epoch 19 [3200/20000] current_loss: 0.000972\n",
            "Train: epoch 19 [4800/20000] current_loss: 0.000494\n",
            "Train: epoch 19 [6400/20000] current_loss: 0.000715\n",
            "Train: epoch 19 [8000/20000] current_loss: 0.001007\n",
            "Train: epoch 19 [9600/20000] current_loss: 0.000971\n",
            "Train: epoch 19 [11200/20000] current_loss: 0.000648\n",
            "Train: epoch 19 [12800/20000] current_loss: 0.001058\n",
            "Train: epoch 19 [14400/20000] current_loss: 0.001688\n",
            "Train: epoch 19 [16000/20000] current_loss: 0.001125\n",
            "Train: epoch 19 [17600/20000] current_loss: 0.001223\n",
            "Train: epoch 19 [19200/20000] current_loss: 0.001848\n",
            "Train: epoch 19 Average loss: 0.0017\n",
            "Val:   epoch 19 [0/4000] current_loss: 0.000606\n",
            "Val:   epoch 19 [400/4000] current_loss: 0.000247\n",
            "Val:   epoch 19 [800/4000] current_loss: 0.004510\n",
            "Val:   epoch 19 [1200/4000] current_loss: 0.000286\n",
            "Val:   epoch 19 [1600/4000] current_loss: 0.000268\n",
            "Val:   epoch 19 [2000/4000] current_loss: 0.002414\n",
            "Val:   epoch 19 [2400/4000] current_loss: 0.000111\n",
            "Val:   epoch 19 [2800/4000] current_loss: 0.000593\n",
            "Val:   epoch 19 [3200/4000] current_loss: 0.000682\n",
            "Val:   epoch 19 [3600/4000] current_loss: 0.000152\n",
            "Val:   epoch 19 Average loss: 0.0004\n",
            "\n",
            "\n",
            "Epoch 20/50\n",
            "Train: epoch 20 [0/20000] current_loss: 0.000787\n",
            "Train: epoch 20 [1600/20000] current_loss: 0.004056\n",
            "Train: epoch 20 [3200/20000] current_loss: 0.001068\n",
            "Train: epoch 20 [4800/20000] current_loss: 0.000940\n",
            "Train: epoch 20 [6400/20000] current_loss: 0.002204\n",
            "Train: epoch 20 [8000/20000] current_loss: 0.000736\n",
            "Train: epoch 20 [9600/20000] current_loss: 0.009182\n",
            "Train: epoch 20 [11200/20000] current_loss: 0.001042\n",
            "Train: epoch 20 [12800/20000] current_loss: 0.000321\n",
            "Train: epoch 20 [14400/20000] current_loss: 0.001218\n",
            "Train: epoch 20 [16000/20000] current_loss: 0.001752\n",
            "Train: epoch 20 [17600/20000] current_loss: 0.000782\n",
            "Train: epoch 20 [19200/20000] current_loss: 0.001527\n",
            "Train: epoch 20 Average loss: 0.0016\n",
            "Val:   epoch 20 [0/4000] current_loss: 0.000868\n",
            "Val:   epoch 20 [400/4000] current_loss: 0.004481\n",
            "Val:   epoch 20 [800/4000] current_loss: 0.000606\n",
            "Val:   epoch 20 [1200/4000] current_loss: 0.001730\n",
            "Val:   epoch 20 [1600/4000] current_loss: 0.001350\n",
            "Val:   epoch 20 [2000/4000] current_loss: 0.000487\n",
            "Val:   epoch 20 [2400/4000] current_loss: 0.000822\n",
            "Val:   epoch 20 [2800/4000] current_loss: 0.000800\n",
            "Val:   epoch 20 [3200/4000] current_loss: 0.001024\n",
            "Val:   epoch 20 [3600/4000] current_loss: 0.000737\n",
            "Val:   epoch 20 Average loss: 0.0006\n",
            "\n",
            "\n",
            "Epoch 21/50\n",
            "Train: epoch 21 [0/20000] current_loss: 0.000903\n",
            "Train: epoch 21 [1600/20000] current_loss: 0.000934\n",
            "Train: epoch 21 [3200/20000] current_loss: 0.000793\n",
            "Train: epoch 21 [4800/20000] current_loss: 0.000496\n",
            "Train: epoch 21 [6400/20000] current_loss: 0.000745\n",
            "Train: epoch 21 [8000/20000] current_loss: 0.000478\n",
            "Train: epoch 21 [9600/20000] current_loss: 0.000807\n",
            "Train: epoch 21 [11200/20000] current_loss: 0.003919\n",
            "Train: epoch 21 [12800/20000] current_loss: 0.000794\n",
            "Train: epoch 21 [14400/20000] current_loss: 0.000968\n",
            "Train: epoch 21 [16000/20000] current_loss: 0.000773\n",
            "Train: epoch 21 [17600/20000] current_loss: 0.001079\n",
            "Train: epoch 21 [19200/20000] current_loss: 0.000889\n",
            "Train: epoch 21 Average loss: 0.0015\n",
            "Val:   epoch 21 [0/4000] current_loss: 0.001847\n",
            "Val:   epoch 21 [400/4000] current_loss: 0.000167\n",
            "Val:   epoch 21 [800/4000] current_loss: 0.000199\n",
            "Val:   epoch 21 [1200/4000] current_loss: 0.001503\n",
            "Val:   epoch 21 [1600/4000] current_loss: 0.000553\n",
            "Val:   epoch 21 [2000/4000] current_loss: 0.000694\n",
            "Val:   epoch 21 [2400/4000] current_loss: 0.000176\n",
            "Val:   epoch 21 [2800/4000] current_loss: 0.000516\n",
            "Val:   epoch 21 [3200/4000] current_loss: 0.001521\n",
            "Val:   epoch 21 [3600/4000] current_loss: 0.000793\n",
            "Val:   epoch 21 Average loss: 0.0004\n",
            "\n",
            "\n",
            "Epoch 22/50\n",
            "Train: epoch 22 [0/20000] current_loss: 0.000655\n",
            "Train: epoch 22 [1600/20000] current_loss: 0.001063\n",
            "Train: epoch 22 [3200/20000] current_loss: 0.001255\n",
            "Train: epoch 22 [4800/20000] current_loss: 0.001697\n",
            "Train: epoch 22 [6400/20000] current_loss: 0.001700\n",
            "Train: epoch 22 [8000/20000] current_loss: 0.000574\n",
            "Train: epoch 22 [9600/20000] current_loss: 0.000689\n",
            "Train: epoch 22 [11200/20000] current_loss: 0.000802\n",
            "Train: epoch 22 [12800/20000] current_loss: 0.000380\n",
            "Train: epoch 22 [14400/20000] current_loss: 0.001111\n",
            "Train: epoch 22 [16000/20000] current_loss: 0.001068\n",
            "Train: epoch 22 [17600/20000] current_loss: 0.000906\n",
            "Train: epoch 22 [19200/20000] current_loss: 0.001793\n",
            "Train: epoch 22 Average loss: 0.0015\n",
            "Val:   epoch 22 [0/4000] current_loss: 0.000129\n",
            "Val:   epoch 22 [400/4000] current_loss: 0.000253\n",
            "Val:   epoch 22 [800/4000] current_loss: 0.002173\n",
            "Val:   epoch 22 [1200/4000] current_loss: 0.000664\n",
            "Val:   epoch 22 [1600/4000] current_loss: 0.000156\n",
            "Val:   epoch 22 [2000/4000] current_loss: 0.001112\n",
            "Val:   epoch 22 [2400/4000] current_loss: 0.000649\n",
            "Val:   epoch 22 [2800/4000] current_loss: 0.000696\n",
            "Val:   epoch 22 [3200/4000] current_loss: 0.001276\n",
            "Val:   epoch 22 [3600/4000] current_loss: 0.000641\n",
            "Val:   epoch 22 Average loss: 0.0005\n",
            "\n",
            "\n",
            "Epoch 23/50\n",
            "Train: epoch 23 [0/20000] current_loss: 0.000557\n",
            "Train: epoch 23 [1600/20000] current_loss: 0.000606\n",
            "Train: epoch 23 [3200/20000] current_loss: 0.001166\n",
            "Train: epoch 23 [4800/20000] current_loss: 0.000671\n",
            "Train: epoch 23 [6400/20000] current_loss: 0.001053\n",
            "Train: epoch 23 [8000/20000] current_loss: 0.005666\n",
            "Train: epoch 23 [9600/20000] current_loss: 0.004669\n",
            "Train: epoch 23 [11200/20000] current_loss: 0.000641\n",
            "Train: epoch 23 [12800/20000] current_loss: 0.000587\n",
            "Train: epoch 23 [14400/20000] current_loss: 0.000894\n",
            "Train: epoch 23 [16000/20000] current_loss: 0.001201\n",
            "Train: epoch 23 [17600/20000] current_loss: 0.000559\n",
            "Train: epoch 23 [19200/20000] current_loss: 0.001115\n",
            "Train: epoch 23 Average loss: 0.0015\n",
            "Val:   epoch 23 [0/4000] current_loss: 0.001244\n",
            "Val:   epoch 23 [400/4000] current_loss: 0.000850\n",
            "Val:   epoch 23 [800/4000] current_loss: 0.001977\n",
            "Val:   epoch 23 [1200/4000] current_loss: 0.000542\n",
            "Val:   epoch 23 [1600/4000] current_loss: 0.000383\n",
            "Val:   epoch 23 [2000/4000] current_loss: 0.000220\n",
            "Val:   epoch 23 [2400/4000] current_loss: 0.001547\n",
            "Val:   epoch 23 [2800/4000] current_loss: 0.001978\n",
            "Val:   epoch 23 [3200/4000] current_loss: 0.000710\n",
            "Val:   epoch 23 [3600/4000] current_loss: 0.000430\n",
            "Val:   epoch 23 Average loss: 0.0004\n",
            "\n",
            "\n",
            "Epoch 24/50\n",
            "Train: epoch 24 [0/20000] current_loss: 0.000622\n",
            "Train: epoch 24 [1600/20000] current_loss: 0.000618\n",
            "Train: epoch 24 [3200/20000] current_loss: 0.000552\n",
            "Train: epoch 24 [4800/20000] current_loss: 0.000570\n",
            "Train: epoch 24 [6400/20000] current_loss: 0.000657\n",
            "Train: epoch 24 [8000/20000] current_loss: 0.000957\n",
            "Train: epoch 24 [9600/20000] current_loss: 0.000814\n",
            "Train: epoch 24 [11200/20000] current_loss: 0.001120\n",
            "Train: epoch 24 [12800/20000] current_loss: 0.000655\n",
            "Train: epoch 24 [14400/20000] current_loss: 0.000417\n",
            "Train: epoch 24 [16000/20000] current_loss: 0.000885\n",
            "Train: epoch 24 [17600/20000] current_loss: 0.000986\n",
            "Train: epoch 24 [19200/20000] current_loss: 0.000486\n",
            "Train: epoch 24 Average loss: 0.0015\n",
            "Val:   epoch 24 [0/4000] current_loss: 0.000452\n",
            "Val:   epoch 24 [400/4000] current_loss: 0.000205\n",
            "Val:   epoch 24 [800/4000] current_loss: 0.000619\n",
            "Val:   epoch 24 [1200/4000] current_loss: 0.001371\n",
            "Val:   epoch 24 [1600/4000] current_loss: 0.000789\n",
            "Val:   epoch 24 [2000/4000] current_loss: 0.000781\n",
            "Val:   epoch 24 [2400/4000] current_loss: 0.000493\n",
            "Val:   epoch 24 [2800/4000] current_loss: 0.001459\n",
            "Val:   epoch 24 [3200/4000] current_loss: 0.001464\n",
            "Val:   epoch 24 [3600/4000] current_loss: 0.000497\n",
            "Val:   epoch 24 Average loss: 0.0004\n",
            "\n",
            "\n",
            "Epoch 25/50\n",
            "Train: epoch 25 [0/20000] current_loss: 0.000907\n",
            "Train: epoch 25 [1600/20000] current_loss: 0.000905\n",
            "Train: epoch 25 [3200/20000] current_loss: 0.000702\n",
            "Train: epoch 25 [4800/20000] current_loss: 0.001859\n",
            "Train: epoch 25 [6400/20000] current_loss: 0.000873\n",
            "Train: epoch 25 [8000/20000] current_loss: 0.000674\n",
            "Train: epoch 25 [9600/20000] current_loss: 0.000640\n",
            "Train: epoch 25 [11200/20000] current_loss: 0.000516\n",
            "Train: epoch 25 [12800/20000] current_loss: 0.000659\n",
            "Train: epoch 25 [14400/20000] current_loss: 0.000842\n",
            "Train: epoch 25 [16000/20000] current_loss: 0.000949\n",
            "Train: epoch 25 [17600/20000] current_loss: 0.048116\n",
            "Train: epoch 25 [19200/20000] current_loss: 0.000716\n",
            "Train: epoch 25 Average loss: 0.0014\n",
            "Val:   epoch 25 [0/4000] current_loss: 0.000163\n",
            "Val:   epoch 25 [400/4000] current_loss: 0.001480\n",
            "Val:   epoch 25 [800/4000] current_loss: 0.000715\n",
            "Val:   epoch 25 [1200/4000] current_loss: 0.000233\n",
            "Val:   epoch 25 [1600/4000] current_loss: 0.000535\n",
            "Val:   epoch 25 [2000/4000] current_loss: 0.001860\n",
            "Val:   epoch 25 [2400/4000] current_loss: 0.000945\n",
            "Val:   epoch 25 [2800/4000] current_loss: 0.004535\n",
            "Val:   epoch 25 [3200/4000] current_loss: 0.000197\n",
            "Val:   epoch 25 [3600/4000] current_loss: 0.000182\n",
            "Val:   epoch 25 Average loss: 0.0004\n",
            "\n",
            "\n",
            "Epoch 26/50\n",
            "Train: epoch 26 [0/20000] current_loss: 0.000426\n",
            "Train: epoch 26 [1600/20000] current_loss: 0.000425\n",
            "Train: epoch 26 [3200/20000] current_loss: 0.000292\n",
            "Train: epoch 26 [4800/20000] current_loss: 0.001211\n",
            "Train: epoch 26 [6400/20000] current_loss: 0.000923\n",
            "Train: epoch 26 [8000/20000] current_loss: 0.001251\n",
            "Train: epoch 26 [9600/20000] current_loss: 0.022742\n",
            "Train: epoch 26 [11200/20000] current_loss: 0.001389\n",
            "Train: epoch 26 [12800/20000] current_loss: 0.000433\n",
            "Train: epoch 26 [14400/20000] current_loss: 0.000781\n",
            "Train: epoch 26 [16000/20000] current_loss: 0.000451\n",
            "Train: epoch 26 [17600/20000] current_loss: 0.001621\n",
            "Train: epoch 26 [19200/20000] current_loss: 0.001681\n",
            "Train: epoch 26 Average loss: 0.0014\n",
            "Val:   epoch 26 [0/4000] current_loss: 0.000508\n",
            "Val:   epoch 26 [400/4000] current_loss: 0.000637\n",
            "Val:   epoch 26 [800/4000] current_loss: 0.000706\n",
            "Val:   epoch 26 [1200/4000] current_loss: 0.000389\n",
            "Val:   epoch 26 [1600/4000] current_loss: 0.000827\n",
            "Val:   epoch 26 [2000/4000] current_loss: 0.000474\n",
            "Val:   epoch 26 [2400/4000] current_loss: 0.000349\n",
            "Val:   epoch 26 [2800/4000] current_loss: 0.001113\n",
            "Val:   epoch 26 [3200/4000] current_loss: 0.000718\n",
            "Val:   epoch 26 [3600/4000] current_loss: 0.000226\n",
            "Val:   epoch 26 Average loss: 0.0004\n",
            "\n",
            "\n",
            "Epoch 27/50\n",
            "Train: epoch 27 [0/20000] current_loss: 0.000512\n",
            "Train: epoch 27 [1600/20000] current_loss: 0.001125\n",
            "Train: epoch 27 [3200/20000] current_loss: 0.000606\n",
            "Train: epoch 27 [4800/20000] current_loss: 0.001300\n",
            "Train: epoch 27 [6400/20000] current_loss: 0.000812\n",
            "Train: epoch 27 [8000/20000] current_loss: 0.000799\n",
            "Train: epoch 27 [9600/20000] current_loss: 0.000716\n",
            "Train: epoch 27 [11200/20000] current_loss: 0.000517\n",
            "Train: epoch 27 [12800/20000] current_loss: 0.002509\n",
            "Train: epoch 27 [14400/20000] current_loss: 0.000977\n",
            "Train: epoch 27 [16000/20000] current_loss: 0.000889\n",
            "Train: epoch 27 [17600/20000] current_loss: 0.000495\n",
            "Train: epoch 27 [19200/20000] current_loss: 0.000703\n",
            "Train: epoch 27 Average loss: 0.0014\n",
            "Val:   epoch 27 [0/4000] current_loss: 0.001071\n",
            "Val:   epoch 27 [400/4000] current_loss: 0.004123\n",
            "Val:   epoch 27 [800/4000] current_loss: 0.000362\n",
            "Val:   epoch 27 [1200/4000] current_loss: 0.000182\n",
            "Val:   epoch 27 [1600/4000] current_loss: 0.000645\n",
            "Val:   epoch 27 [2000/4000] current_loss: 0.032365\n",
            "Val:   epoch 27 [2400/4000] current_loss: 0.000668\n",
            "Val:   epoch 27 [2800/4000] current_loss: 0.000770\n",
            "Val:   epoch 27 [3200/4000] current_loss: 0.000313\n",
            "Val:   epoch 27 [3600/4000] current_loss: 0.000253\n",
            "Val:   epoch 27 Average loss: 0.0004\n",
            "\n",
            "\n",
            "Epoch 28/50\n",
            "Train: epoch 28 [0/20000] current_loss: 0.001428\n",
            "Train: epoch 28 [1600/20000] current_loss: 0.001070\n",
            "Train: epoch 28 [3200/20000] current_loss: 0.000489\n",
            "Train: epoch 28 [4800/20000] current_loss: 0.000749\n",
            "Train: epoch 28 [6400/20000] current_loss: 0.000447\n",
            "Train: epoch 28 [8000/20000] current_loss: 0.000874\n",
            "Train: epoch 28 [9600/20000] current_loss: 0.000566\n",
            "Train: epoch 28 [11200/20000] current_loss: 0.000438\n",
            "Train: epoch 28 [12800/20000] current_loss: 0.000502\n",
            "Train: epoch 28 [14400/20000] current_loss: 0.000411\n",
            "Train: epoch 28 [16000/20000] current_loss: 0.000542\n",
            "Train: epoch 28 [17600/20000] current_loss: 0.000360\n",
            "Train: epoch 28 [19200/20000] current_loss: 0.000438\n",
            "Train: epoch 28 Average loss: 0.0014\n",
            "Val:   epoch 28 [0/4000] current_loss: 0.000693\n",
            "Val:   epoch 28 [400/4000] current_loss: 0.000940\n",
            "Val:   epoch 28 [800/4000] current_loss: 0.001649\n",
            "Val:   epoch 28 [1200/4000] current_loss: 0.000199\n",
            "Val:   epoch 28 [1600/4000] current_loss: 0.000378\n",
            "Val:   epoch 28 [2000/4000] current_loss: 0.001247\n",
            "Val:   epoch 28 [2400/4000] current_loss: 0.000399\n",
            "Val:   epoch 28 [2800/4000] current_loss: 0.000150\n",
            "Val:   epoch 28 [3200/4000] current_loss: 0.000413\n",
            "Val:   epoch 28 [3600/4000] current_loss: 0.000572\n",
            "Val:   epoch 28 Average loss: 0.0003\n",
            "\n",
            "\n",
            "Epoch 29/50\n",
            "Train: epoch 29 [0/20000] current_loss: 0.000488\n",
            "Train: epoch 29 [1600/20000] current_loss: 0.000573\n",
            "Train: epoch 29 [3200/20000] current_loss: 0.000439\n",
            "Train: epoch 29 [4800/20000] current_loss: 0.000488\n",
            "Train: epoch 29 [6400/20000] current_loss: 0.000567\n",
            "Train: epoch 29 [8000/20000] current_loss: 0.000666\n",
            "Train: epoch 29 [9600/20000] current_loss: 0.001432\n",
            "Train: epoch 29 [11200/20000] current_loss: 0.000783\n",
            "Train: epoch 29 [12800/20000] current_loss: 0.000544\n",
            "Train: epoch 29 [14400/20000] current_loss: 0.000850\n",
            "Train: epoch 29 [16000/20000] current_loss: 0.000768\n",
            "Train: epoch 29 [17600/20000] current_loss: 0.000628\n",
            "Train: epoch 29 [19200/20000] current_loss: 0.000915\n",
            "Train: epoch 29 Average loss: 0.0013\n",
            "Val:   epoch 29 [0/4000] current_loss: 0.000980\n",
            "Val:   epoch 29 [400/4000] current_loss: 0.000300\n",
            "Val:   epoch 29 [800/4000] current_loss: 0.000509\n",
            "Val:   epoch 29 [1200/4000] current_loss: 0.000522\n",
            "Val:   epoch 29 [1600/4000] current_loss: 0.003031\n",
            "Val:   epoch 29 [2000/4000] current_loss: 0.001456\n",
            "Val:   epoch 29 [2400/4000] current_loss: 0.001163\n",
            "Val:   epoch 29 [2800/4000] current_loss: 0.001427\n",
            "Val:   epoch 29 [3200/4000] current_loss: 0.000886\n",
            "Val:   epoch 29 [3600/4000] current_loss: 0.000737\n",
            "Val:   epoch 29 Average loss: 0.0003\n",
            "\n",
            "\n",
            "Epoch 30/50\n",
            "Train: epoch 30 [0/20000] current_loss: 0.000585\n",
            "Train: epoch 30 [1600/20000] current_loss: 0.000636\n",
            "Train: epoch 30 [3200/20000] current_loss: 0.000433\n",
            "Train: epoch 30 [4800/20000] current_loss: 0.001695\n",
            "Train: epoch 30 [6400/20000] current_loss: 0.000397\n",
            "Train: epoch 30 [8000/20000] current_loss: 0.000844\n",
            "Train: epoch 30 [9600/20000] current_loss: 0.000795\n",
            "Train: epoch 30 [11200/20000] current_loss: 0.001427\n",
            "Train: epoch 30 [12800/20000] current_loss: 0.001297\n",
            "Train: epoch 30 [14400/20000] current_loss: 0.005579\n",
            "Train: epoch 30 [16000/20000] current_loss: 0.001271\n",
            "Train: epoch 30 [17600/20000] current_loss: 0.000946\n",
            "Train: epoch 30 [19200/20000] current_loss: 0.001192\n",
            "Train: epoch 30 Average loss: 0.0014\n",
            "Val:   epoch 30 [0/4000] current_loss: 0.000543\n",
            "Val:   epoch 30 [400/4000] current_loss: 0.001580\n",
            "Val:   epoch 30 [800/4000] current_loss: 0.000640\n",
            "Val:   epoch 30 [1200/4000] current_loss: 0.000868\n",
            "Val:   epoch 30 [1600/4000] current_loss: 0.000652\n",
            "Val:   epoch 30 [2000/4000] current_loss: 0.000391\n",
            "Val:   epoch 30 [2400/4000] current_loss: 0.000579\n",
            "Val:   epoch 30 [2800/4000] current_loss: 0.000380\n",
            "Val:   epoch 30 [3200/4000] current_loss: 0.000889\n",
            "Val:   epoch 30 [3600/4000] current_loss: 0.000446\n",
            "Val:   epoch 30 Average loss: 0.0004\n",
            "\n",
            "\n",
            "Epoch 31/50\n",
            "Train: epoch 31 [0/20000] current_loss: 0.000606\n",
            "Train: epoch 31 [1600/20000] current_loss: 0.000583\n",
            "Train: epoch 31 [3200/20000] current_loss: 0.000955\n",
            "Train: epoch 31 [4800/20000] current_loss: 0.000504\n",
            "Train: epoch 31 [6400/20000] current_loss: 0.000362\n",
            "Train: epoch 31 [8000/20000] current_loss: 0.000404\n",
            "Train: epoch 31 [9600/20000] current_loss: 0.000766\n",
            "Train: epoch 31 [11200/20000] current_loss: 0.001595\n",
            "Train: epoch 31 [12800/20000] current_loss: 0.001131\n",
            "Train: epoch 31 [14400/20000] current_loss: 0.000601\n",
            "Train: epoch 31 [16000/20000] current_loss: 0.000780\n",
            "Train: epoch 31 [17600/20000] current_loss: 0.000482\n",
            "Train: epoch 31 [19200/20000] current_loss: 0.000460\n",
            "Train: epoch 31 Average loss: 0.0013\n",
            "Val:   epoch 31 [0/4000] current_loss: 0.000260\n",
            "Val:   epoch 31 [400/4000] current_loss: 0.000980\n",
            "Val:   epoch 31 [800/4000] current_loss: 0.000317\n",
            "Val:   epoch 31 [1200/4000] current_loss: 0.000253\n",
            "Val:   epoch 31 [1600/4000] current_loss: 0.000422\n",
            "Val:   epoch 31 [2000/4000] current_loss: 0.000353\n",
            "Val:   epoch 31 [2400/4000] current_loss: 0.000536\n",
            "Val:   epoch 31 [2800/4000] current_loss: 0.000382\n",
            "Val:   epoch 31 [3200/4000] current_loss: 0.000368\n",
            "Val:   epoch 31 [3600/4000] current_loss: 0.000283\n",
            "Val:   epoch 31 Average loss: 0.0003\n",
            "\n",
            "\n",
            "Epoch 32/50\n",
            "Train: epoch 32 [0/20000] current_loss: 0.000747\n",
            "Train: epoch 32 [1600/20000] current_loss: 0.000868\n",
            "Train: epoch 32 [3200/20000] current_loss: 0.000627\n",
            "Train: epoch 32 [4800/20000] current_loss: 0.000271\n",
            "Train: epoch 32 [6400/20000] current_loss: 0.000904\n",
            "Train: epoch 32 [8000/20000] current_loss: 0.000621\n",
            "Train: epoch 32 [9600/20000] current_loss: 0.000459\n",
            "Train: epoch 32 [11200/20000] current_loss: 0.000814\n",
            "Train: epoch 32 [12800/20000] current_loss: 0.000799\n",
            "Train: epoch 32 [14400/20000] current_loss: 0.000940\n",
            "Train: epoch 32 [16000/20000] current_loss: 0.000459\n",
            "Train: epoch 32 [17600/20000] current_loss: 0.000915\n",
            "Train: epoch 32 [19200/20000] current_loss: 0.000777\n",
            "Train: epoch 32 Average loss: 0.0013\n",
            "Val:   epoch 32 [0/4000] current_loss: 0.000648\n",
            "Val:   epoch 32 [400/4000] current_loss: 0.001543\n",
            "Val:   epoch 32 [800/4000] current_loss: 0.000284\n",
            "Val:   epoch 32 [1200/4000] current_loss: 0.000363\n",
            "Val:   epoch 32 [1600/4000] current_loss: 0.000433\n",
            "Val:   epoch 32 [2000/4000] current_loss: 0.000370\n",
            "Val:   epoch 32 [2400/4000] current_loss: 0.000413\n",
            "Val:   epoch 32 [2800/4000] current_loss: 0.002887\n",
            "Val:   epoch 32 [3200/4000] current_loss: 0.000316\n",
            "Val:   epoch 32 [3600/4000] current_loss: 0.000364\n",
            "Val:   epoch 32 Average loss: 0.0004\n",
            "\n",
            "\n",
            "Epoch 33/50\n",
            "Train: epoch 33 [0/20000] current_loss: 0.000435\n",
            "Train: epoch 33 [1600/20000] current_loss: 0.000403\n",
            "Train: epoch 33 [3200/20000] current_loss: 0.001318\n",
            "Train: epoch 33 [4800/20000] current_loss: 0.001431\n",
            "Train: epoch 33 [6400/20000] current_loss: 0.000558\n",
            "Train: epoch 33 [8000/20000] current_loss: 0.000506\n",
            "Train: epoch 33 [9600/20000] current_loss: 0.000658\n",
            "Train: epoch 33 [11200/20000] current_loss: 0.000576\n",
            "Train: epoch 33 [12800/20000] current_loss: 0.000424\n",
            "Train: epoch 33 [14400/20000] current_loss: 0.000724\n",
            "Train: epoch 33 [16000/20000] current_loss: 0.000558\n",
            "Train: epoch 33 [17600/20000] current_loss: 0.000199\n",
            "Train: epoch 33 [19200/20000] current_loss: 0.000518\n",
            "Train: epoch 33 Average loss: 0.0013\n",
            "Val:   epoch 33 [0/4000] current_loss: 0.001232\n",
            "Val:   epoch 33 [400/4000] current_loss: 0.001714\n",
            "Val:   epoch 33 [800/4000] current_loss: 0.000332\n",
            "Val:   epoch 33 [1200/4000] current_loss: 0.000149\n",
            "Val:   epoch 33 [1600/4000] current_loss: 0.000809\n",
            "Val:   epoch 33 [2000/4000] current_loss: 0.000673\n",
            "Val:   epoch 33 [2400/4000] current_loss: 0.000606\n",
            "Val:   epoch 33 [2800/4000] current_loss: 0.000517\n",
            "Val:   epoch 33 [3200/4000] current_loss: 0.000920\n",
            "Val:   epoch 33 [3600/4000] current_loss: 0.000625\n",
            "Val:   epoch 33 Average loss: 0.0005\n",
            "\n",
            "\n",
            "Epoch 34/50\n",
            "Train: epoch 34 [0/20000] current_loss: 0.001024\n",
            "Train: epoch 34 [1600/20000] current_loss: 0.000755\n",
            "Train: epoch 34 [3200/20000] current_loss: 0.000878\n",
            "Train: epoch 34 [4800/20000] current_loss: 0.000564\n",
            "Train: epoch 34 [6400/20000] current_loss: 0.000530\n",
            "Train: epoch 34 [8000/20000] current_loss: 0.014049\n",
            "Train: epoch 34 [9600/20000] current_loss: 0.001065\n",
            "Train: epoch 34 [11200/20000] current_loss: 0.000427\n",
            "Train: epoch 34 [12800/20000] current_loss: 0.000984\n",
            "Train: epoch 34 [14400/20000] current_loss: 0.001286\n",
            "Train: epoch 34 [16000/20000] current_loss: 0.000320\n",
            "Train: epoch 34 [17600/20000] current_loss: 0.001187\n",
            "Train: epoch 34 [19200/20000] current_loss: 0.000558\n",
            "Train: epoch 34 Average loss: 0.0012\n",
            "Val:   epoch 34 [0/4000] current_loss: 0.000183\n",
            "Val:   epoch 34 [400/4000] current_loss: 0.001907\n",
            "Val:   epoch 34 [800/4000] current_loss: 0.000248\n",
            "Val:   epoch 34 [1200/4000] current_loss: 0.000154\n",
            "Val:   epoch 34 [1600/4000] current_loss: 0.000735\n",
            "Val:   epoch 34 [2000/4000] current_loss: 0.000144\n",
            "Val:   epoch 34 [2400/4000] current_loss: 0.000343\n",
            "Val:   epoch 34 [2800/4000] current_loss: 0.001237\n",
            "Val:   epoch 34 [3200/4000] current_loss: 0.000940\n",
            "Val:   epoch 34 [3600/4000] current_loss: 0.000552\n",
            "Val:   epoch 34 Average loss: 0.0004\n",
            "\n",
            "\n",
            "Epoch 35/50\n",
            "Train: epoch 35 [0/20000] current_loss: 0.001801\n",
            "Train: epoch 35 [1600/20000] current_loss: 0.001020\n",
            "Train: epoch 35 [3200/20000] current_loss: 0.000351\n",
            "Train: epoch 35 [4800/20000] current_loss: 0.000430\n",
            "Train: epoch 35 [6400/20000] current_loss: 0.000534\n",
            "Train: epoch 35 [8000/20000] current_loss: 0.000746\n",
            "Train: epoch 35 [9600/20000] current_loss: 0.000370\n",
            "Train: epoch 35 [11200/20000] current_loss: 0.000449\n",
            "Train: epoch 35 [12800/20000] current_loss: 0.001071\n",
            "Train: epoch 35 [14400/20000] current_loss: 0.000352\n",
            "Train: epoch 35 [16000/20000] current_loss: 0.000414\n",
            "Train: epoch 35 [17600/20000] current_loss: 0.000429\n",
            "Train: epoch 35 [19200/20000] current_loss: 0.000845\n",
            "Train: epoch 35 Average loss: 0.0013\n",
            "Val:   epoch 35 [0/4000] current_loss: 0.000966\n",
            "Val:   epoch 35 [400/4000] current_loss: 0.000425\n",
            "Val:   epoch 35 [800/4000] current_loss: 0.000375\n",
            "Val:   epoch 35 [1200/4000] current_loss: 0.000311\n",
            "Val:   epoch 35 [1600/4000] current_loss: 0.004073\n",
            "Val:   epoch 35 [2000/4000] current_loss: 0.000258\n",
            "Val:   epoch 35 [2400/4000] current_loss: 0.000914\n",
            "Val:   epoch 35 [2800/4000] current_loss: 0.004620\n",
            "Val:   epoch 35 [3200/4000] current_loss: 0.000297\n",
            "Val:   epoch 35 [3600/4000] current_loss: 0.000638\n",
            "Val:   epoch 35 Average loss: 0.0004\n",
            "\n",
            "\n",
            "Epoch 36/50\n",
            "Train: epoch 36 [0/20000] current_loss: 0.000912\n",
            "Train: epoch 36 [1600/20000] current_loss: 0.001640\n",
            "Train: epoch 36 [3200/20000] current_loss: 0.000348\n",
            "Train: epoch 36 [4800/20000] current_loss: 0.000901\n",
            "Train: epoch 36 [6400/20000] current_loss: 0.000424\n",
            "Train: epoch 36 [8000/20000] current_loss: 0.000734\n",
            "Train: epoch 36 [9600/20000] current_loss: 0.001130\n",
            "Train: epoch 36 [11200/20000] current_loss: 0.000488\n",
            "Train: epoch 36 [12800/20000] current_loss: 0.000962\n",
            "Train: epoch 36 [14400/20000] current_loss: 0.000617\n",
            "Train: epoch 36 [16000/20000] current_loss: 0.000483\n",
            "Train: epoch 36 [17600/20000] current_loss: 0.000682\n",
            "Train: epoch 36 [19200/20000] current_loss: 0.001113\n",
            "Train: epoch 36 Average loss: 0.0012\n",
            "Val:   epoch 36 [0/4000] current_loss: 0.000845\n",
            "Val:   epoch 36 [400/4000] current_loss: 0.000478\n",
            "Val:   epoch 36 [800/4000] current_loss: 0.000869\n",
            "Val:   epoch 36 [1200/4000] current_loss: 0.000297\n",
            "Val:   epoch 36 [1600/4000] current_loss: 0.001145\n",
            "Val:   epoch 36 [2000/4000] current_loss: 0.000290\n",
            "Val:   epoch 36 [2400/4000] current_loss: 0.000503\n",
            "Val:   epoch 36 [2800/4000] current_loss: 0.001134\n",
            "Val:   epoch 36 [3200/4000] current_loss: 0.000767\n",
            "Val:   epoch 36 [3600/4000] current_loss: 0.000776\n",
            "Val:   epoch 36 Average loss: 0.0004\n",
            "\n",
            "\n",
            "Epoch 37/50\n",
            "Train: epoch 37 [0/20000] current_loss: 0.000614\n",
            "Train: epoch 37 [1600/20000] current_loss: 0.000636\n",
            "Train: epoch 37 [3200/20000] current_loss: 0.000579\n",
            "Train: epoch 37 [4800/20000] current_loss: 0.000648\n",
            "Train: epoch 37 [6400/20000] current_loss: 0.000783\n",
            "Train: epoch 37 [8000/20000] current_loss: 0.000677\n",
            "Train: epoch 37 [9600/20000] current_loss: 0.001537\n",
            "Train: epoch 37 [11200/20000] current_loss: 0.000780\n",
            "Train: epoch 37 [12800/20000] current_loss: 0.000880\n",
            "Train: epoch 37 [14400/20000] current_loss: 0.000783\n",
            "Train: epoch 37 [16000/20000] current_loss: 0.000687\n",
            "Train: epoch 37 [17600/20000] current_loss: 0.000926\n",
            "Train: epoch 37 [19200/20000] current_loss: 0.000387\n",
            "Train: epoch 37 Average loss: 0.0011\n",
            "Val:   epoch 37 [0/4000] current_loss: 0.000426\n",
            "Val:   epoch 37 [400/4000] current_loss: 0.000840\n",
            "Val:   epoch 37 [800/4000] current_loss: 0.000099\n",
            "Val:   epoch 37 [1200/4000] current_loss: 0.000451\n",
            "Val:   epoch 37 [1600/4000] current_loss: 0.000259\n",
            "Val:   epoch 37 [2000/4000] current_loss: 0.000476\n",
            "Val:   epoch 37 [2400/4000] current_loss: 0.000502\n",
            "Val:   epoch 37 [2800/4000] current_loss: 0.001961\n",
            "Val:   epoch 37 [3200/4000] current_loss: 0.001101\n",
            "Val:   epoch 37 [3600/4000] current_loss: 0.011012\n",
            "Val:   epoch 37 Average loss: 0.0004\n",
            "\n",
            "\n",
            "Epoch 38/50\n",
            "Train: epoch 38 [0/20000] current_loss: 0.000355\n",
            "Train: epoch 38 [1600/20000] current_loss: 0.001230\n",
            "Train: epoch 38 [3200/20000] current_loss: 0.000713\n",
            "Train: epoch 38 [4800/20000] current_loss: 0.000621\n",
            "Train: epoch 38 [6400/20000] current_loss: 0.000379\n",
            "Train: epoch 38 [8000/20000] current_loss: 0.000465\n",
            "Train: epoch 38 [9600/20000] current_loss: 0.000563\n",
            "Train: epoch 38 [11200/20000] current_loss: 0.000695\n",
            "Train: epoch 38 [12800/20000] current_loss: 0.000853\n",
            "Train: epoch 38 [14400/20000] current_loss: 0.000630\n",
            "Train: epoch 38 [16000/20000] current_loss: 0.000563\n",
            "Train: epoch 38 [17600/20000] current_loss: 0.004279\n",
            "Train: epoch 38 [19200/20000] current_loss: 0.000416\n",
            "Train: epoch 38 Average loss: 0.0009\n",
            "Val:   epoch 38 [0/4000] current_loss: 0.000937\n",
            "Val:   epoch 38 [400/4000] current_loss: 0.000707\n",
            "Val:   epoch 38 [800/4000] current_loss: 0.041875\n",
            "Val:   epoch 38 [1200/4000] current_loss: 0.001134\n",
            "Val:   epoch 38 [1600/4000] current_loss: 0.000398\n",
            "Val:   epoch 38 [2000/4000] current_loss: 0.002721\n",
            "Val:   epoch 38 [2400/4000] current_loss: 0.000349\n",
            "Val:   epoch 38 [2800/4000] current_loss: 0.000912\n",
            "Val:   epoch 38 [3200/4000] current_loss: 0.009371\n",
            "Val:   epoch 38 [3600/4000] current_loss: 0.001470\n",
            "Val:   epoch 38 Average loss: 0.0004\n",
            "\n",
            "\n",
            "Epoch 39/50\n",
            "Train: epoch 39 [0/20000] current_loss: 0.000451\n",
            "Train: epoch 39 [1600/20000] current_loss: 0.000287\n",
            "Train: epoch 39 [3200/20000] current_loss: 0.000481\n",
            "Train: epoch 39 [4800/20000] current_loss: 0.000675\n",
            "Train: epoch 39 [6400/20000] current_loss: 0.000450\n",
            "Train: epoch 39 [8000/20000] current_loss: 0.000604\n",
            "Train: epoch 39 [9600/20000] current_loss: 0.000894\n",
            "Train: epoch 39 [11200/20000] current_loss: 0.000673\n",
            "Train: epoch 39 [12800/20000] current_loss: 0.000664\n",
            "Train: epoch 39 [14400/20000] current_loss: 0.000840\n",
            "Train: epoch 39 [16000/20000] current_loss: 0.000369\n",
            "Train: epoch 39 [17600/20000] current_loss: 0.000599\n",
            "Train: epoch 39 [19200/20000] current_loss: 0.001064\n",
            "Train: epoch 39 Average loss: 0.0008\n",
            "Val:   epoch 39 [0/4000] current_loss: 0.001378\n",
            "Val:   epoch 39 [400/4000] current_loss: 0.000592\n",
            "Val:   epoch 39 [800/4000] current_loss: 0.000721\n",
            "Val:   epoch 39 [1200/4000] current_loss: 0.000757\n",
            "Val:   epoch 39 [1600/4000] current_loss: 0.000563\n",
            "Val:   epoch 39 [2000/4000] current_loss: 0.000548\n",
            "Val:   epoch 39 [2400/4000] current_loss: 0.000884\n",
            "Val:   epoch 39 [2800/4000] current_loss: 0.000528\n",
            "Val:   epoch 39 [3200/4000] current_loss: 0.000883\n",
            "Val:   epoch 39 [3600/4000] current_loss: 0.000283\n",
            "Val:   epoch 39 Average loss: 0.0004\n",
            "\n",
            "\n",
            "Epoch 40/50\n",
            "Train: epoch 40 [0/20000] current_loss: 0.001172\n",
            "Train: epoch 40 [1600/20000] current_loss: 0.000533\n",
            "Train: epoch 40 [3200/20000] current_loss: 0.000391\n",
            "Train: epoch 40 [4800/20000] current_loss: 0.000590\n",
            "Train: epoch 40 [6400/20000] current_loss: 0.000408\n",
            "Train: epoch 40 [8000/20000] current_loss: 0.000520\n",
            "Train: epoch 40 [9600/20000] current_loss: 0.000408\n",
            "Train: epoch 40 [11200/20000] current_loss: 0.000459\n",
            "Train: epoch 40 [12800/20000] current_loss: 0.000410\n",
            "Train: epoch 40 [14400/20000] current_loss: 0.000697\n",
            "Train: epoch 40 [16000/20000] current_loss: 0.000429\n",
            "Train: epoch 40 [17600/20000] current_loss: 0.000362\n",
            "Train: epoch 40 [19200/20000] current_loss: 0.000877\n",
            "Train: epoch 40 Average loss: 0.0008\n",
            "Val:   epoch 40 [0/4000] current_loss: 0.000703\n",
            "Val:   epoch 40 [400/4000] current_loss: 0.000426\n",
            "Val:   epoch 40 [800/4000] current_loss: 0.003147\n",
            "Val:   epoch 40 [1200/4000] current_loss: 0.000420\n",
            "Val:   epoch 40 [1600/4000] current_loss: 0.000573\n",
            "Val:   epoch 40 [2000/4000] current_loss: 0.000726\n",
            "Val:   epoch 40 [2400/4000] current_loss: 0.000162\n",
            "Val:   epoch 40 [2800/4000] current_loss: 0.000403\n",
            "Val:   epoch 40 [3200/4000] current_loss: 0.000297\n",
            "Val:   epoch 40 [3600/4000] current_loss: 0.000756\n",
            "Val:   epoch 40 Average loss: 0.0004\n",
            "\n",
            "\n",
            "Epoch 41/50\n",
            "Train: epoch 41 [0/20000] current_loss: 0.000556\n",
            "Train: epoch 41 [1600/20000] current_loss: 0.000771\n",
            "Train: epoch 41 [3200/20000] current_loss: 0.000463\n",
            "Train: epoch 41 [4800/20000] current_loss: 0.000660\n",
            "Train: epoch 41 [6400/20000] current_loss: 0.000684\n",
            "Train: epoch 41 [8000/20000] current_loss: 0.000523\n",
            "Train: epoch 41 [9600/20000] current_loss: 0.000471\n",
            "Train: epoch 41 [11200/20000] current_loss: 0.000359\n",
            "Train: epoch 41 [12800/20000] current_loss: 0.000565\n",
            "Train: epoch 41 [14400/20000] current_loss: 0.000461\n",
            "Train: epoch 41 [16000/20000] current_loss: 0.001592\n",
            "Train: epoch 41 [17600/20000] current_loss: 0.002593\n",
            "Train: epoch 41 [19200/20000] current_loss: 0.000735\n",
            "Train: epoch 41 Average loss: 0.0009\n",
            "Val:   epoch 41 [0/4000] current_loss: 0.001533\n",
            "Val:   epoch 41 [400/4000] current_loss: 0.001142\n",
            "Val:   epoch 41 [800/4000] current_loss: 0.000629\n",
            "Val:   epoch 41 [1200/4000] current_loss: 0.001593\n",
            "Val:   epoch 41 [1600/4000] current_loss: 0.001380\n",
            "Val:   epoch 41 [2000/4000] current_loss: 0.000933\n",
            "Val:   epoch 41 [2400/4000] current_loss: 0.000770\n",
            "Val:   epoch 41 [2800/4000] current_loss: 0.000214\n",
            "Val:   epoch 41 [3200/4000] current_loss: 0.000376\n",
            "Val:   epoch 41 [3600/4000] current_loss: 0.000664\n",
            "Val:   epoch 41 Average loss: 0.0004\n",
            "\n",
            "\n",
            "Epoch 42/50\n",
            "Train: epoch 42 [0/20000] current_loss: 0.000470\n",
            "Train: epoch 42 [1600/20000] current_loss: 0.000563\n",
            "Train: epoch 42 [3200/20000] current_loss: 0.000675\n",
            "Train: epoch 42 [4800/20000] current_loss: 0.000661\n",
            "Train: epoch 42 [6400/20000] current_loss: 0.000585\n",
            "Train: epoch 42 [8000/20000] current_loss: 0.000320\n",
            "Train: epoch 42 [9600/20000] current_loss: 0.001174\n",
            "Train: epoch 42 [11200/20000] current_loss: 0.001279\n",
            "Train: epoch 42 [12800/20000] current_loss: 0.000819\n",
            "Train: epoch 42 [14400/20000] current_loss: 0.000979\n",
            "Train: epoch 42 [16000/20000] current_loss: 0.009109\n",
            "Train: epoch 42 [17600/20000] current_loss: 0.000382\n",
            "Train: epoch 42 [19200/20000] current_loss: 0.000690\n",
            "Train: epoch 42 Average loss: 0.0008\n",
            "Val:   epoch 42 [0/4000] current_loss: 0.000442\n",
            "Val:   epoch 42 [400/4000] current_loss: 0.000216\n",
            "Val:   epoch 42 [800/4000] current_loss: 0.001622\n",
            "Val:   epoch 42 [1200/4000] current_loss: 0.000549\n",
            "Val:   epoch 42 [1600/4000] current_loss: 0.001569\n",
            "Val:   epoch 42 [2000/4000] current_loss: 0.000864\n",
            "Val:   epoch 42 [2400/4000] current_loss: 0.000554\n",
            "Val:   epoch 42 [2800/4000] current_loss: 0.000737\n",
            "Val:   epoch 42 [3200/4000] current_loss: 0.000592\n",
            "Val:   epoch 42 [3600/4000] current_loss: 0.000387\n",
            "Val:   epoch 42 Average loss: 0.0005\n",
            "\n",
            "\n",
            "Epoch 43/50\n",
            "Train: epoch 43 [0/20000] current_loss: 0.001270\n",
            "Train: epoch 43 [1600/20000] current_loss: 0.000587\n",
            "Train: epoch 43 [3200/20000] current_loss: 0.000432\n",
            "Train: epoch 43 [4800/20000] current_loss: 0.000267\n",
            "Train: epoch 43 [6400/20000] current_loss: 0.001188\n",
            "Train: epoch 43 [8000/20000] current_loss: 0.000414\n",
            "Train: epoch 43 [9600/20000] current_loss: 0.000644\n",
            "Train: epoch 43 [11200/20000] current_loss: 0.000372\n",
            "Train: epoch 43 [12800/20000] current_loss: 0.001858\n",
            "Train: epoch 43 [14400/20000] current_loss: 0.000402\n",
            "Train: epoch 43 [16000/20000] current_loss: 0.000338\n",
            "Train: epoch 43 [17600/20000] current_loss: 0.000282\n",
            "Train: epoch 43 [19200/20000] current_loss: 0.001033\n",
            "Train: epoch 43 Average loss: 0.0007\n",
            "Val:   epoch 43 [0/4000] current_loss: 0.000403\n",
            "Val:   epoch 43 [400/4000] current_loss: 0.000448\n",
            "Val:   epoch 43 [800/4000] current_loss: 0.001642\n",
            "Val:   epoch 43 [1200/4000] current_loss: 0.001892\n",
            "Val:   epoch 43 [1600/4000] current_loss: 0.000760\n",
            "Val:   epoch 43 [2000/4000] current_loss: 0.000390\n",
            "Val:   epoch 43 [2400/4000] current_loss: 0.000670\n",
            "Val:   epoch 43 [2800/4000] current_loss: 0.001188\n",
            "Val:   epoch 43 [3200/4000] current_loss: 0.000846\n",
            "Val:   epoch 43 [3600/4000] current_loss: 0.000831\n",
            "Val:   epoch 43 Average loss: 0.0004\n",
            "\n",
            "\n",
            "Epoch 44/50\n",
            "Train: epoch 44 [0/20000] current_loss: 0.000535\n",
            "Train: epoch 44 [1600/20000] current_loss: 0.000393\n",
            "Train: epoch 44 [3200/20000] current_loss: 0.001731\n",
            "Train: epoch 44 [4800/20000] current_loss: 0.000735\n",
            "Train: epoch 44 [6400/20000] current_loss: 0.001105\n",
            "Train: epoch 44 [8000/20000] current_loss: 0.000672\n",
            "Train: epoch 44 [9600/20000] current_loss: 0.002016\n",
            "Train: epoch 44 [11200/20000] current_loss: 0.000810\n",
            "Train: epoch 44 [12800/20000] current_loss: 0.000574\n",
            "Train: epoch 44 [14400/20000] current_loss: 0.000644\n",
            "Train: epoch 44 [16000/20000] current_loss: 0.000789\n",
            "Train: epoch 44 [17600/20000] current_loss: 0.000586\n",
            "Train: epoch 44 [19200/20000] current_loss: 0.000846\n",
            "Train: epoch 44 Average loss: 0.0007\n",
            "Val:   epoch 44 [0/4000] current_loss: 0.000704\n",
            "Val:   epoch 44 [400/4000] current_loss: 0.000904\n",
            "Val:   epoch 44 [800/4000] current_loss: 0.000372\n",
            "Val:   epoch 44 [1200/4000] current_loss: 0.000922\n",
            "Val:   epoch 44 [1600/4000] current_loss: 0.001108\n",
            "Val:   epoch 44 [2000/4000] current_loss: 0.000316\n",
            "Val:   epoch 44 [2400/4000] current_loss: 0.000351\n",
            "Val:   epoch 44 [2800/4000] current_loss: 0.000157\n",
            "Val:   epoch 44 [3200/4000] current_loss: 0.000875\n",
            "Val:   epoch 44 [3600/4000] current_loss: 0.000286\n",
            "Val:   epoch 44 Average loss: 0.0003\n",
            "\n",
            "\n",
            "Epoch 45/50\n",
            "Train: epoch 45 [0/20000] current_loss: 0.000373\n",
            "Train: epoch 45 [1600/20000] current_loss: 0.000867\n",
            "Train: epoch 45 [3200/20000] current_loss: 0.000456\n",
            "Train: epoch 45 [4800/20000] current_loss: 0.000895\n",
            "Train: epoch 45 [6400/20000] current_loss: 0.001205\n",
            "Train: epoch 45 [8000/20000] current_loss: 0.000375\n",
            "Train: epoch 45 [9600/20000] current_loss: 0.000565\n",
            "Train: epoch 45 [11200/20000] current_loss: 0.000263\n",
            "Train: epoch 45 [12800/20000] current_loss: 0.000606\n",
            "Train: epoch 45 [14400/20000] current_loss: 0.000830\n",
            "Train: epoch 45 [16000/20000] current_loss: 0.001070\n",
            "Train: epoch 45 [17600/20000] current_loss: 0.001156\n",
            "Train: epoch 45 [19200/20000] current_loss: 0.000340\n",
            "Train: epoch 45 Average loss: 0.0008\n",
            "Val:   epoch 45 [0/4000] current_loss: 0.001448\n",
            "Val:   epoch 45 [400/4000] current_loss: 0.000753\n",
            "Val:   epoch 45 [800/4000] current_loss: 0.000702\n",
            "Val:   epoch 45 [1200/4000] current_loss: 0.000488\n",
            "Val:   epoch 45 [1600/4000] current_loss: 0.000629\n",
            "Val:   epoch 45 [2000/4000] current_loss: 0.002316\n",
            "Val:   epoch 45 [2400/4000] current_loss: 0.001306\n",
            "Val:   epoch 45 [2800/4000] current_loss: 0.001066\n",
            "Val:   epoch 45 [3200/4000] current_loss: 0.000510\n",
            "Val:   epoch 45 [3600/4000] current_loss: 0.003508\n",
            "Val:   epoch 45 Average loss: 0.0005\n",
            "\n",
            "\n",
            "Epoch 46/50\n",
            "Train: epoch 46 [0/20000] current_loss: 0.000756\n",
            "Train: epoch 46 [1600/20000] current_loss: 0.000325\n",
            "Train: epoch 46 [3200/20000] current_loss: 0.000402\n",
            "Train: epoch 46 [4800/20000] current_loss: 0.000731\n",
            "Train: epoch 46 [6400/20000] current_loss: 0.000881\n",
            "Train: epoch 46 [8000/20000] current_loss: 0.000224\n",
            "Train: epoch 46 [9600/20000] current_loss: 0.000319\n",
            "Train: epoch 46 [11200/20000] current_loss: 0.000366\n",
            "Train: epoch 46 [12800/20000] current_loss: 0.000759\n",
            "Train: epoch 46 [14400/20000] current_loss: 0.000800\n",
            "Train: epoch 46 [16000/20000] current_loss: 0.000724\n",
            "Train: epoch 46 [17600/20000] current_loss: 0.000512\n",
            "Train: epoch 46 [19200/20000] current_loss: 0.000563\n",
            "Train: epoch 46 Average loss: 0.0007\n",
            "Val:   epoch 46 [0/4000] current_loss: 0.001316\n",
            "Val:   epoch 46 [400/4000] current_loss: 0.002218\n",
            "Val:   epoch 46 [800/4000] current_loss: 0.001424\n",
            "Val:   epoch 46 [1200/4000] current_loss: 0.000457\n",
            "Val:   epoch 46 [1600/4000] current_loss: 0.001212\n",
            "Val:   epoch 46 [2000/4000] current_loss: 0.000620\n",
            "Val:   epoch 46 [2400/4000] current_loss: 0.000848\n",
            "Val:   epoch 46 [2800/4000] current_loss: 0.001255\n",
            "Val:   epoch 46 [3200/4000] current_loss: 0.000811\n",
            "Val:   epoch 46 [3600/4000] current_loss: 0.003544\n",
            "Val:   epoch 46 Average loss: 0.0005\n",
            "\n",
            "\n",
            "Epoch 47/50\n",
            "Train: epoch 47 [0/20000] current_loss: 0.000511\n",
            "Train: epoch 47 [1600/20000] current_loss: 0.000399\n",
            "Train: epoch 47 [3200/20000] current_loss: 0.000402\n",
            "Train: epoch 47 [4800/20000] current_loss: 0.000820\n",
            "Train: epoch 47 [6400/20000] current_loss: 0.000309\n",
            "Train: epoch 47 [8000/20000] current_loss: 0.000662\n",
            "Train: epoch 47 [9600/20000] current_loss: 0.000235\n",
            "Train: epoch 47 [11200/20000] current_loss: 0.000449\n",
            "Train: epoch 47 [12800/20000] current_loss: 0.000571\n",
            "Train: epoch 47 [14400/20000] current_loss: 0.000365\n",
            "Train: epoch 47 [16000/20000] current_loss: 0.000335\n",
            "Train: epoch 47 [17600/20000] current_loss: 0.000447\n",
            "Train: epoch 47 [19200/20000] current_loss: 0.002005\n",
            "Train: epoch 47 Average loss: 0.0008\n",
            "Val:   epoch 47 [0/4000] current_loss: 0.001166\n",
            "Val:   epoch 47 [400/4000] current_loss: 0.000705\n",
            "Val:   epoch 47 [800/4000] current_loss: 0.000487\n",
            "Val:   epoch 47 [1200/4000] current_loss: 0.000356\n",
            "Val:   epoch 47 [1600/4000] current_loss: 0.000253\n",
            "Val:   epoch 47 [2000/4000] current_loss: 0.000299\n",
            "Val:   epoch 47 [2400/4000] current_loss: 0.000499\n",
            "Val:   epoch 47 [2800/4000] current_loss: 0.000688\n",
            "Val:   epoch 47 [3200/4000] current_loss: 0.000437\n",
            "Val:   epoch 47 [3600/4000] current_loss: 0.000854\n",
            "Val:   epoch 47 Average loss: 0.0005\n",
            "\n",
            "\n",
            "Epoch 48/50\n",
            "Train: epoch 48 [0/20000] current_loss: 0.001252\n",
            "Train: epoch 48 [1600/20000] current_loss: 0.000663\n",
            "Train: epoch 48 [3200/20000] current_loss: 0.000283\n",
            "Train: epoch 48 [4800/20000] current_loss: 0.000492\n",
            "Train: epoch 48 [6400/20000] current_loss: 0.000436\n",
            "Train: epoch 48 [8000/20000] current_loss: 0.000314\n",
            "Train: epoch 48 [9600/20000] current_loss: 0.000279\n",
            "Train: epoch 48 [11200/20000] current_loss: 0.000761\n",
            "Train: epoch 48 [12800/20000] current_loss: 0.000365\n",
            "Train: epoch 48 [14400/20000] current_loss: 0.000443\n",
            "Train: epoch 48 [16000/20000] current_loss: 0.000471\n",
            "Train: epoch 48 [17600/20000] current_loss: 0.000364\n",
            "Train: epoch 48 [19200/20000] current_loss: 0.000846\n",
            "Train: epoch 48 Average loss: 0.0007\n",
            "Val:   epoch 48 [0/4000] current_loss: 0.000957\n",
            "Val:   epoch 48 [400/4000] current_loss: 0.000343\n",
            "Val:   epoch 48 [800/4000] current_loss: 0.000239\n",
            "Val:   epoch 48 [1200/4000] current_loss: 0.000363\n",
            "Val:   epoch 48 [1600/4000] current_loss: 0.000283\n",
            "Val:   epoch 48 [2000/4000] current_loss: 0.001233\n",
            "Val:   epoch 48 [2400/4000] current_loss: 0.000515\n",
            "Val:   epoch 48 [2800/4000] current_loss: 0.001062\n",
            "Val:   epoch 48 [3200/4000] current_loss: 0.000760\n",
            "Val:   epoch 48 [3600/4000] current_loss: 0.000227\n",
            "Val:   epoch 48 Average loss: 0.0004\n",
            "\n",
            "\n",
            "Epoch 49/50\n",
            "Train: epoch 49 [0/20000] current_loss: 0.000421\n",
            "Train: epoch 49 [1600/20000] current_loss: 0.000238\n",
            "Train: epoch 49 [3200/20000] current_loss: 0.000922\n",
            "Train: epoch 49 [4800/20000] current_loss: 0.000620\n",
            "Train: epoch 49 [6400/20000] current_loss: 0.000398\n",
            "Train: epoch 49 [8000/20000] current_loss: 0.000438\n",
            "Train: epoch 49 [9600/20000] current_loss: 0.000283\n",
            "Train: epoch 49 [11200/20000] current_loss: 0.000677\n",
            "Train: epoch 49 [12800/20000] current_loss: 0.000314\n",
            "Train: epoch 49 [14400/20000] current_loss: 0.000343\n",
            "Train: epoch 49 [16000/20000] current_loss: 0.000572\n",
            "Train: epoch 49 [17600/20000] current_loss: 0.000261\n",
            "Train: epoch 49 [19200/20000] current_loss: 0.000497\n",
            "Train: epoch 49 Average loss: 0.0006\n",
            "Val:   epoch 49 [0/4000] current_loss: 0.000382\n",
            "Val:   epoch 49 [400/4000] current_loss: 0.000293\n",
            "Val:   epoch 49 [800/4000] current_loss: 0.000240\n",
            "Val:   epoch 49 [1200/4000] current_loss: 0.000871\n",
            "Val:   epoch 49 [1600/4000] current_loss: 0.000071\n",
            "Val:   epoch 49 [2000/4000] current_loss: 0.001796\n",
            "Val:   epoch 49 [2400/4000] current_loss: 0.000315\n",
            "Val:   epoch 49 [2800/4000] current_loss: 0.004319\n",
            "Val:   epoch 49 [3200/4000] current_loss: 0.000182\n",
            "Val:   epoch 49 [3600/4000] current_loss: 0.000138\n",
            "Val:   epoch 49 Average loss: 0.0003\n",
            "\n",
            "\n"
          ],
          "name": "stdout"
        },
        {
          "output_type": "display_data",
          "data": {
            "image/png": "iVBORw0KGgoAAAANSUhEUgAAAfcAAAGDCAYAAAA2xlnwAAAABHNCSVQICAgIfAhkiAAAAAlwSFlz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\nAAAASUVORK5CYII=\n",
            "text/plain": [
              "<Figure size 576x432 with 1 Axes>"
            ]
          },
          "metadata": {
            "tags": []
          }
        },
        {
          "output_type": "stream",
          "text": [
            "Saving Model.\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "colab_type": "text",
        "id": "Ga5ScsFRYwZh"
      },
      "source": [
        "# Run Tests"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "iSB5cA5QuLQd",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "def iou(params0, params1):\n",
        "    row0, col0, rad0 = params0\n",
        "    row1, col1, rad1 = params1\n",
        "\n",
        "    shape0 = Point(row0, col0).buffer(rad0)\n",
        "    shape1 = Point(row1, col1).buffer(rad1)\n",
        "\n",
        "    return (\n",
        "        shape0.intersection(shape1).area /\n",
        "        shape0.union(shape1).area\n",
        "    )"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "hwuz5ubQuCZt",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "def find_circle(img, device, model): \n",
        "    # Fill in this function\n",
        "    img = img.astype(np.float32)\n",
        "    img  = torch.from_numpy(img).unsqueeze(0) # add channel dimension\n",
        "    data = img.to(device)\n",
        "\n",
        "    with torch.no_grad():\n",
        "      data = data.unsqueeze(0) # batch size 1\n",
        "      output = model(data)\n",
        "    \n",
        "    output = output.cpu() * maxlength\n",
        "    result = output.numpy().flatten()\n",
        "    return result"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "ez8MNXTXucmx",
        "colab_type": "code",
        "outputId": "282d4659-cdda-4b14-aaa5-55242ef7c5d2",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 104
        }
      },
      "source": [
        "def main():\n",
        "    print(\"_____Circle Detection_____\")\n",
        "\n",
        "    #Load model\n",
        "    device = torch.device(\"cuda\" if torch.cuda.is_available() else \"cpu\")\n",
        "    trained_model = WORK_FOLDER + '/model_mse_20k_5e-3_50epochs.pth' #'/model_5e-3_50epochs.pth'\n",
        "    model = CircleDetector()\n",
        "    print(\"Device :\",device)\n",
        "    print(\"Model  : Circle Detector\")\n",
        "    print(\"Parms  :\",count_parameters(model))    \n",
        "    \n",
        "    #Load weights\n",
        "    if(not torch.cuda.is_available()):\n",
        "        model.load_state_dict(torch.load(trained_model, map_location=lambda storage, loc: storage))\n",
        "    else:\n",
        "        model = model.to(device)\n",
        "        model.load_state_dict(torch.load(trained_model))\n",
        "\n",
        "    model.eval()\n",
        "\n",
        "    # Run tests\n",
        "    results = []\n",
        "    for _ in range(1000):\n",
        "        params, img = noisy_circle(200, 50, 2)\n",
        "        detected = find_circle(img, device, model)\n",
        "        results.append(iou(params, detected))\n",
        "    results = np.array(results)\n",
        "\n",
        "    print(\"AP over 1000 runs:\",(results > 0.7).mean())\n",
        "    del model\n",
        "\n",
        "main()"
      ],
      "execution_count": 116,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "_____Circle Detection_____\n",
            "Device : cuda\n",
            "Model  : Circle Detector\n",
            "Parms  : 345859\n",
            "AP over 1000 runs: 0.931\n"
          ],
          "name": "stdout"
        }
      ]
    }
  ]
}